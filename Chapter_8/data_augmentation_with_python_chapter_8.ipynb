{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DlWAB8G4ijz"
      },
      "source": [
        "# 🌻 Welcome to Chapter 8, Audio Data Augmentation with Spectrogram\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I am glad to see you using this Python Notebook. 🐶\n",
        "\n",
        "The Python Notebook is an integral part of the book. You can add new “code cells” to extend the functions, add your data, and explore new possibilities, such as downloading additional real-world datasets from the Kaggle website and coding the **Fun challenges**. Furthermore, the book has **Fun facts**, in-depth discussion about augmentation techniques, and Pluto, an imaginary Siberian Huskey coding companion. Together they will guide you every steps of the way.\n",
        "\n",
        "Pluto encourages you to copy or save a copy of this Python Notebook to your local space and add the “text cells” to keep your notes. In other words, read the book and copy the relevant concept to this Python Notebook’s text-cells. Thus, you can have the explanation, note, original code, your code, and any crazy future ideas in one place.  \n",
        "\n",
        "\n",
        "💗 I hope you enjoy reading the book and hacking code as much as I enjoy writing it.\n",
        "\n",
        "\n",
        "## 🌟 Amazon Book\n",
        "\n",
        "---\n",
        "\n",
        "- The book is available on the Amazon Book website:\n",
        "  - https://www.amazon.com/dp/1803246456\n",
        "\n",
        "  - Author: Duc Haba\n",
        "  - Published: 2023\n",
        "  - Page count: 390+\n",
        "\n",
        "\n",
        "- The original Python Notebook is on:\n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/Chapter_8/data_augmentation_with_python_chapter_8.ipynb\n",
        "\n",
        "- 🚀 Click on the blue \"Open in Colab\" button at the top of this page to begin hacking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ8-JIXv6jmV"
      },
      "source": [
        "# 😀 Excerpt from Chapter 8, Audio Data Augmentation with Spectrogram\n",
        "\n",
        "---\n",
        "\n",
        "> In case you haven’t bought the book. Here is an teaser from the first page of Chapter 8.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In the previous chapter, we visualized the sound using the Waveform graph. An audio spectrogram is another visualizing method to see the audio components. The inputs to the Spectrogram are a one-dimensional array of amplitude values and the sampling rate. They are the same inputs as the Waveform graph.\n",
        "\n",
        "An audio Spectrogram is sometimes called a sonograph, sonogram, voiceprint, or voicegram. The Spectrogram is a more detailed representation of sound than the Waveform graph. It shows a correlation between frequency and amplitude (loudness) over time, which helps visualize the frequency content in a signal. Spectrogram makes it easier to identify musical elements, detect melodic patterns, recognize frequency-based effects, and compare the results of different volume settings. Additionally, the Spectrogram can be more helpful in identifying non-musical aspects of a signal, such as noise and interference from other frequencies.\n",
        "\n",
        "The typical usage is for music, human speech, and sonar. A short standard definition is a spectrum of frequency maps with time duration. In other words, the y axis is the frequency in Hz or kHz, and the x axis is the time duration in seconds or milliseconds. Sometimes, the graph comes with a color index for the amplitude level.\n",
        "\n",
        "Pluto will explain the code in the Python Notebook later in the chapter, but here is a sneak peek of an audio Spectrogram. The command for drawing the control piano scale in the D major audio file is as follows:\n",
        "\n",
        "\n",
        "> skip...image...\n",
        "\n",
        "Before Pluto demystifies the audio Spectrogram, you should review Chapter 7 if the audio concepts and keywords sound alien to you. Chapter 8 relies heavily on the knowledge and practices in Chapter 7.\n",
        "\n",
        "In Figure 8.1, Pluto uses the Matplotlib library to draw the audio Spectrogram. The primary input is the amplitude array and the sampling rate. The library does all the heavy calculations, and other libraries, such as the Librosa or the SciPy library, can perform the same task. In particular, Matplotlib can generate many types of audio Spectrogram from the same input. Pluto will dig deeper into types of Spectrogram a bit later, but first, let’s break down the steps of how the library constructs an audio Spectrogram. The five high-level tasks are as follows:\n",
        "\n",
        "1. Splitting the audio stream into overlapping segments, also known as windows.\n",
        "\n",
        "2. Calculating the Short Time Fourier Transformation (STFT) value on each window.\n",
        "\n",
        "3. Converting the windows’ value into decibels (dB).\n",
        "\n",
        "4. Linking the windows together as in the original audio sequence.\n",
        "\n",
        "5. Displaying the result in a graph with the y axis as Hz, the x axis as seconds, and dB as a color-coded value.\n",
        "\n",
        "The math for the previous five steps is complex, and the chapter’s goal is to use a Spectrogram to visualize the sound and augment the audio file. Thus, we rely on audio libraries to perform the math calculation.\n",
        "\n",
        "As mentioned, the underlying data representing the Spectrogram is the same as the Waveform format. Therefore, the audio augmentation techniques are the same. Consequently, the resulting augmented audio file will sound the same. The visual representation is the only difference between the Spectrogram and the Waveform graph.\n",
        "\n",
        "The majority of this chapter will cover the audio Spectrogram standard format, variation of a Spectrogram, Mel-spectrogram, and Chroma STFT. The augmentation techniques represent a shorter section because you have learned the method in the previous chapter. We will cover the following topics in this chapter:\n",
        "\n",
        "- Initialize and download\n",
        "\n",
        "- Audio Spectrogram\n",
        "\n",
        "- Various Spectrogram formats\n",
        "\n",
        "- Mel-spectrogram and Chroma STFT\n",
        "\n",
        "- Spectrogram augmentation\n",
        "\n",
        "- Spectrogram image\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "🌴 *end of excerpt from the book*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b52gSlp60SN"
      },
      "source": [
        "# GitHub Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oeDAu1u6zWf"
      },
      "outputs": [],
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9buwUR767Te"
      },
      "outputs": [],
      "source": [
        "url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLTEzhHWi5xg"
      },
      "outputs": [],
      "source": [
        "# (optional) list the notebook magic commands\n",
        "# %lsmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOawA01L7Ok0"
      },
      "source": [
        "## Fetch file from URL (Optional)\n",
        "\n",
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsmQ7rgj67Ww"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nKp0nxT67aH"
      },
      "outputs": [],
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6462KTtr7cFQ"
      },
      "source": [
        "# Run Pluto\n",
        "\n",
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGiTw16ZxVH"
      },
      "outputs": [],
      "source": [
        "# %% CARRY-OVER code install\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "!pip install pyspellchecker\n",
        "!pip install audiomentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3zbkOO86_WB"
      },
      "outputs": [],
      "source": [
        "#load and run the pluto chapter 7 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_7.py'\n",
        "%run {pluto_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhRR0JSf746h"
      },
      "source": [
        "## Verify Pluto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBIw7fiI6_Zy"
      },
      "outputs": [],
      "source": [
        "pluto.say_sys_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmDlzR_Q7zCk"
      },
      "outputs": [],
      "source": [
        "# # (optional) list attributes, function, and everything else\n",
        "# dir(pluto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaURlsasaGuo"
      },
      "source": [
        "## (Optional) Export to .py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfx9Ai5Opyqp"
      },
      "outputs": [],
      "source": [
        "pluto_chapter_8 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_8.py'\n",
        "!cp {pluto_file} {pluto_chapter_8}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ6ap39x8HyF"
      },
      "source": [
        "# ✋ Set up Kaggle username and app Key\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "\n",
        "- STOP: Update your Kaggle access username or key first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf4Obdp-77CL"
      },
      "outputs": [],
      "source": [
        "# %%CARRY-OVER code\n",
        "\n",
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "#\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "#\n",
        "!pip install pyspellchecker\n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "#\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"YOUR_KAGGLE_USERNAME\", \"YOUR_KAGGLE_KEY\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "\n",
        "  \"\"\"\n",
        "  Downloads data from a Kaggle competition.\n",
        "\n",
        "  Args:\n",
        "      cname (str): Name of the competition. Defaults to 'name_of_competition'.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "\n",
        "  \"\"\"\n",
        "  Downloads a Kaggle dataset.\n",
        "\n",
        "  Args:\n",
        "      url (str): URL of the Kaggle dataset.\n",
        "      dest (str): Destination directory. Defaults to 'kaggle'.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfHiMQE8XWp"
      },
      "source": [
        "# Fetch Kaggle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSWTfhPU9YjQ"
      },
      "source": [
        "## Musical Emotions Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TEFhsYs77Go"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/kingofarmy/musical-emotions-classification'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GHi9DnM77Kj"
      },
      "outputs": [],
      "source": [
        "f = 'kaggle/musical-emotions-classification/Train.csv'\n",
        "pluto.df_music_data = pluto.fetch_df(f)\n",
        "pluto.df_music_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zK1p7UBJoEW"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "pluto.version = 7.0\n",
        "# augment full path\n",
        "@add_method(PacktDataAug)\n",
        "def _append_music_full_path(self,x):\n",
        "\n",
        "  \"\"\"\n",
        "  Appends the full path to the given music file.\n",
        "\n",
        "  Args:\n",
        "      x (str): Name of the music file.\n",
        "\n",
        "  Returns:\n",
        "      str: Full path to the music file.\n",
        "  \"\"\"\n",
        "\n",
        "  y = re.findall('([a-zA-Z ]*)\\d*.*', x)[0]\n",
        "  return (f'kaggle/musical-emotions-classification/Audio_Files/Audio_Files/Train/{y}/{x}')\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_music_full_path(self, df):\n",
        "\n",
        "  \"\"\"\n",
        "  Appends the full path to the given music files.\n",
        "\n",
        "  Args:\n",
        "      df (pd.DataFrame): DataFrame containing the music files.\n",
        "\n",
        "  Returns:\n",
        "      pd.DataFrame: DataFrame containing the full paths to the music files.\n",
        "  \"\"\"\n",
        "\n",
        "  df['fname'] = df.ImageID.apply(self._append_music_full_path)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Q_FAadP-Wm"
      },
      "outputs": [],
      "source": [
        "pluto.fetch_music_full_path(pluto.df_music_data)\n",
        "pluto.df_music_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TDs0Iz0RCXb"
      },
      "source": [
        "## Human Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9o4H58gRBcO"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/ejlok1/cremad'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zq3-nbPOFoG"
      },
      "outputs": [],
      "source": [
        "# change method name to make_dir_dframe\n",
        "f = 'kaggle/cremad/AudioWAV'\n",
        "pluto.df_voice_data = pluto.make_dir_dataframe(f)\n",
        "pluto.df_voice_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOGSVseohWVQ"
      },
      "outputs": [],
      "source": [
        "pluto.df_voice_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kxU64ydU4Js"
      },
      "source": [
        "## Urban sound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUGSqM4wUaDH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "url = 'https://www.kaggle.com/datasets/rupakroy/urban-sound-8k'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry1HB_qDUaGv"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# change method name to make_dir_dframe\n",
        "f = 'kaggle/urban-sound-8k/UrbanSound8K/UrbanSound8K/audio'\n",
        "pluto.df_sound_data = pluto.make_dir_dataframe(f)\n",
        "pluto.df_sound_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgYZXile7KL"
      },
      "source": [
        "# Audio control D Major"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGvl5_hsfA42"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "f = 'Data-Augmentation-with-Python/pluto_data/control-d-major.mp3'\n",
        "data_amp, sam_rate, fname = pluto._fetch_audio_data(f)\n",
        "pluto.audio_control_dmajor = [data_amp, sam_rate, fname, f]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaB7rJ4IgL_E"
      },
      "source": [
        "# Double check on Waveform graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg-sQtNhsHrs"
      },
      "outputs": [],
      "source": [
        "# double check on waveform graph from previous chapter\n",
        "pluto._draw_audio(data_amp, sam_rate, 'Original: ' + fname)\n",
        "# display audio\n",
        "display(IPython.display.Audio(data_amp, rate=sam_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pc0SRoc10Ko"
      },
      "source": [
        "# Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nAToGMY-SK1"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_8}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _draw_spectrogram(self, data_amp, sam_rate,\n",
        "  fname='Spectrogram',\n",
        "  window=matplotlib.mlab.window_hanning,\n",
        "  cmap='viridis',\n",
        "  sides='default',\n",
        "  mode='default'):\n",
        "\n",
        "  \"\"\"\n",
        "  Draws a spectrogram of the given audio data.\n",
        "\n",
        "  Args:\n",
        "      data_amp (np.ndarray): Audio data.\n",
        "      sam_rate (int): Sampling rate.\n",
        "      fname (str): Name of the spectrogram. Defaults to 'Spectrogram'.\n",
        "      window (Callable): Windowing function. Defaults to matplotlib.mlab.window_hanning.\n",
        "      cmap (str): Colormap. Defaults to 'viridis'.\n",
        "      sides (str): Which sides of the spectrum to return. Defaults to 'default'.\n",
        "      mode (str): Mode of the spectrogram. Defaults to 'default'.\n",
        "\n",
        "  Returns:\n",
        "      Tuple[np.ndarray, np.ndarray, np.ndarray, matplotlib.axes.Axes]: Spectrogram, frequency array, time array, and axes object.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1, 1, figsize=(11, 5))\n",
        "  spec, freq, ts, ax = pic.specgram(data_amp,\n",
        "    Fs=sam_rate,\n",
        "    window=window,\n",
        "    cmap=cmap,\n",
        "    sides=sides,\n",
        "    mode=mode)\n",
        "  pic.set_xlabel('Time, Sampling Rate: '+str(sam_rate),fontsize=16.)\n",
        "  pic.set_ylabel('Frequency (Hz)',fontsize=16.)\n",
        "  pic.set_title(fname,fontsize=18.0)\n",
        "  #\n",
        "  # display and save image\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return spec, freq, ts, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaERQuFmDsDg"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_8}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def draw_spectrogram(self, df,\n",
        "  fname='Spectrogram',\n",
        "  window=matplotlib.mlab.window_hanning,\n",
        "  cmap='viridis',\n",
        "  sides='default',\n",
        "  mode='default'):\n",
        "\n",
        "  \"\"\"\n",
        "  Draws a spectrogram of the given audio data.\n",
        "\n",
        "  Args:\n",
        "      df (pandas.dataframe): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "      fname (str): Name of the spectrogram. Defaults to 'Spectrogram'.\n",
        "      window (Callable): Windowing function. Defaults to matplotlib.mlab.window_hanning.\n",
        "      cmap (str): Colormap. Defaults to 'viridis'.\n",
        "      sides (str): Which sides of the spectrum to return. Defaults to 'default'.\n",
        "      mode (str): Mode of the spectrogram. Defaults to 'default'.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  if (type(df) is list):\n",
        "    data_amp, sam_rate, fname, lname = df\n",
        "  else:\n",
        "    lname = self._fetch_1_sample(df)\n",
        "    data_amp, sam_rate, fname = self._fetch_audio_data(lname)\n",
        "  #\n",
        "  spec, freq, ts, ax = self._draw_spectrogram(data_amp, sam_rate,\n",
        "    fname='Spectrogram: '+fname,\n",
        "    window=window,\n",
        "    cmap=cmap,\n",
        "    sides=sides,\n",
        "    mode=mode)\n",
        "  # display audio\n",
        "  display(IPython.display.Audio(data_amp,rate=sam_rate))\n",
        "  return\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _draw_melspectrogram(self, mel_db, sam_rate, data_amp,\n",
        "  fname='MelSpectrogram',\n",
        "  cmap='viridis',\n",
        "  y_axis='mel',\n",
        "  y_label='Mel scale (Hz)'):\n",
        "\n",
        "  \"\"\"\n",
        "  Draws a mel-scaled spectrogram of the given audio data.\n",
        "\n",
        "  Args:\n",
        "      mel_db (np.ndarray): Mel-scaled spectrogram.\n",
        "      sam_rate (int): Sampling rate.\n",
        "      data_amp (np.ndarray): Audio data.\n",
        "      fname (str): Name of the spectrogram. Defaults to 'MelSpectrogram'.\n",
        "      cmap (str): Colormap. Defaults to 'viridis'.\n",
        "      y_axis (str): Type of frequency axis. Defaults to 'mel'.\n",
        "      y_label (str): Label for the frequency axis. Defaults to 'Mel scale (Hz)'.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1, 1, figsize=(11, 5))\n",
        "  #\n",
        "  img = librosa.display.specshow(mel_db,\n",
        "    sr=sam_rate,\n",
        "    x_axis='time',\n",
        "    y_axis=y_axis,\n",
        "    fmax=8000,\n",
        "    ax=pic,\n",
        "    cmap=cmap)\n",
        "  canvas.colorbar(img, ax=pic, format='%+2.0f dB')\n",
        "  #\n",
        "  pic.set_xlabel('Time, Sampling Rate: '+str(sam_rate),fontsize=16.)\n",
        "  pic.set_ylabel(y_label,fontsize=16.)\n",
        "  pic.set_title(fname,fontsize=18.0)\n",
        "  #\n",
        "  # display and save image\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  # display audio\n",
        "  display(IPython.display.Audio(data_amp,rate=sam_rate))\n",
        "  return\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def draw_melspectrogram(self, df,\n",
        "  fname='MelSpectrogram',\n",
        "  cmap='viridis',\n",
        "  is_chroma=False):\n",
        "\n",
        "  \"\"\"\n",
        "  Draws a mel-scaled spectrogram of the given audio data.\n",
        "\n",
        "  Args:\n",
        "      df (pandas.dataframe): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "      fname (str): Name of the spectrogram. Defaults to 'MelSpectrogram'.\n",
        "      cmap (str): Colormap. Defaults to 'viridis'.\n",
        "      is_chroma (bool): Whether to draw a chroma STFT instead of a mel-scaled spectrogram. Defaults to False.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  if (type(df) is list):\n",
        "    data_amp, sam_rate, fname, lname = df\n",
        "  else:\n",
        "    lname = self._fetch_1_sample(df)\n",
        "    data_amp, sam_rate, fname = self._fetch_audio_data(lname)\n",
        "  #\n",
        "  if (is_chroma):\n",
        "    mel_db = librosa.feature.chroma_stft(data_amp,\n",
        "      sr=sam_rate)\n",
        "    yax = 'chroma'\n",
        "    ylab = 'Pitch class'\n",
        "    tname = 'Chroma STFT: ' + fname\n",
        "  else:\n",
        "    mel = librosa.feature.melspectrogram(y=data_amp,\n",
        "    sr=sam_rate,\n",
        "    n_mels=128,\n",
        "    fmax=8000)\n",
        "    mel_db = librosa.power_to_db(mel, ref=numpy.max)\n",
        "    yax = 'mel'\n",
        "    ylab = 'Mel scale (Hz)'\n",
        "    tname = 'Melspectrogram: ' + fname\n",
        "  #\n",
        "  self._draw_melspectrogram(mel_db, sam_rate, data_amp,\n",
        "    cmap=cmap,\n",
        "    fname=tname,\n",
        "    y_axis=yax,\n",
        "    y_label = ylab)\n",
        "  return\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTBUoUheB_S3"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.audio_control_dmajor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuL_Xylvh6sn"
      },
      "outputs": [],
      "source": [
        "spec, freq, ts, ax = pluto._draw_spectrogram(pluto.audio_control_dmajor[0], pluto.audio_control_dmajor[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8wWvOPI19ij"
      },
      "source": [
        "## Spectrogram parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLmsia_lFQAO"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_music_data, cmap='plasma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Med4s4HGB_XG"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_voice_data, cmap='cool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzax8BH-B_bW"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_sound_data, cmap='brg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFavMUJSB_ew"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.audio_control_dmajor,\n",
        "  window=matplotlib.mlab.window_none)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl8Ks5x4B_iB"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_voice_data,\n",
        "  cmap='cool',\n",
        "  window=matplotlib.mlab.window_none)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g5G1xJ1B_lA"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.audio_control_dmajor,\n",
        "  window=matplotlib.mlab.window_none,\n",
        "  sides='twosided')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2EG48ypB_of"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_music_data,\n",
        "  cmap='plasma',\n",
        "  sides='twosided')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyU77MWAB_r9"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.audio_control_dmajor,\n",
        "  window=matplotlib.mlab.window_none,\n",
        "  sides='twosided',\n",
        "  mode='angle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtjkWQXeJxki"
      },
      "outputs": [],
      "source": [
        "pluto.draw_spectrogram(pluto.df_sound_data,\n",
        "  cmap='brg',\n",
        "  window=matplotlib.mlab.window_none,\n",
        "  sides='twosided',\n",
        "  mode='angle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QEdDUaIJxn3"
      },
      "outputs": [],
      "source": [
        "pluto.draw_melspectrogram(pluto.audio_control_dmajor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A_uUwyrJxrM"
      },
      "outputs": [],
      "source": [
        "pluto.draw_melspectrogram(pluto.df_voice_data, cmap='cool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu0PF8YHWWjB"
      },
      "outputs": [],
      "source": [
        "pluto.draw_melspectrogram(pluto.audio_control_dmajor, is_chroma=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbtwFGkBJxvp"
      },
      "outputs": [],
      "source": [
        "pluto.draw_melspectrogram(pluto.df_music_data, is_chroma=True, cmap='plasma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ldhm5LVqWWmf"
      },
      "outputs": [],
      "source": [
        "pluto.draw_melspectrogram(pluto.df_sound_data, is_chroma=True, cmap='brg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PukgLsehH7RK"
      },
      "source": [
        "# Time shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTxX760Qr9rT"
      },
      "outputs": [],
      "source": [
        "# %CARRY-OVER\n",
        "\n",
        "!pip install audiomentations\n",
        "#\n",
        "# tested on the following version:\n",
        "# !pip install audiomentations==0.29.0\n",
        "# !pip install librosa==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WFJJUPJB9mu"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "import audiomentations\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_1_sample(self, df, dsize=1):\n",
        "\n",
        "  \"\"\"\n",
        "  Fetches a single sample from the given DataFrame.\n",
        "\n",
        "  Args:\n",
        "      df (pd.DataFrame): DataFrame containing the samples.\n",
        "      dsize (int): Number of samples to fetch. Defaults to 1.\n",
        "\n",
        "  Returns:\n",
        "      str: Name of the fetched sample.\n",
        "  \"\"\"\n",
        "\n",
        "  p = df.sample(dsize)\n",
        "  p.reset_index(drop=True, inplace=True)\n",
        "  return p.fname[0]\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def _audio_transform(self, df, xtransform, title='',is_waveform=True):\n",
        "\n",
        "    \"\"\"\n",
        "    Transforms the given audio data using the specified transformation.\n",
        "\n",
        "    Args:\n",
        "        df (Pandas dataframe): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "        xtransform (Callable): Transformation function.\n",
        "        title (str): Title of the plot. Defaults to ''.\n",
        "        is_waveform (bool): Whether to draw a waveform instead of a spectrogram. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "  if (type(df) is list):\n",
        "    data_amp, sam_rate, fname, lname = self.audio_control_dmajor\n",
        "  else:\n",
        "    lname = self._fetch_1_sample(df)\n",
        "    data_amp, sam_rate, fname = self._fetch_audio_data(lname)\n",
        "  #\n",
        "  xaug = xtransform(data_amp, sample_rate=sam_rate)\n",
        "  if (is_waveform):\n",
        "    # augmented\n",
        "    self._draw_audio(xaug, sam_rate, title + ' Augmented: ' + fname)\n",
        "    display(IPython.display.Audio(xaug, rate=sam_rate))\n",
        "    # original\n",
        "    self._draw_audio(data_amp, sam_rate, 'Original: ' + fname)\n",
        "  else:\n",
        "    xdata = [xaug, sam_rate, fname, 'cat']\n",
        "    self.draw_spectrogram(xdata)\n",
        "    self.draw_melspectrogram(xdata)\n",
        "    self.draw_melspectrogram(xdata,is_chroma=True)\n",
        "  display(IPython.display.Audio(data_amp, rate=sam_rate))\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5FLws7qC6NO"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def play_aug_time_shift(self, df, min_fraction=-0.2,\n",
        "  max_fraction=0.8,rollover=True,title='Time Shift', is_waveform=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Plays the audio data after applying time shift augmentation.\n",
        "\n",
        "  Args:\n",
        "      df (Pandas.dataframe): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "      min_fraction (float): Minimum fraction of shift. Defaults to -0.2.\n",
        "      max_fraction (float): Maximum fraction of shift. Defaults to 0.8.\n",
        "      rollover (bool): Whether to roll over the audio data. Defaults to True.\n",
        "      title (str): Title of the plot. Defaults to 'Time Shift'.\n",
        "      is_waveform (bool): Whether to draw a waveform instead of a spectrogram. Defaults to True.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  xtransform = audiomentations.Shift(\n",
        "    min_fraction = min_fraction,\n",
        "    max_fraction = max_fraction,\n",
        "    rollover = rollover,\n",
        "    p=1.0\n",
        "  )\n",
        "  self._audio_transform(df, xtransform, title=title,is_waveform=is_waveform)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u15bwOFWMi3f"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_time_shift(pluto.audio_control_dmajor, min_fraction=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMvYsxTDQ2JZ"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_time_shift(pluto.audio_control_dmajor, min_fraction=0.8, is_waveform=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LllZAQK2SxxX"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_time_shift(pluto.df_voice_data, min_fraction=0.6, is_waveform=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EWF8w9DxGP9"
      },
      "source": [
        "# Time stretch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvtnmRBJMi7e"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def play_aug_time_stretch(self, df, min_rate=0.2,max_rate=6.8,\n",
        "  leave_length_unchanged=True,title='Time Stretch',\n",
        "  is_waveform=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Plays the audio data after applying time stretch augmentation.\n",
        "\n",
        "  Args:\n",
        "      df (Union[str, List[Union[str, np.ndarray]]]): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "      min_rate (float): Minimum rate of stretch. Defaults to 0.2.\n",
        "      max_rate (float): Maximum rate of stretch. Defaults to 6.8.\n",
        "      leave_length_unchanged (bool): Whether to leave the length unchanged. Defaults to True.\n",
        "      title (str): Title of the plot. Defaults to 'Time Stretch'.\n",
        "      is_waveform (bool): Whether to draw a waveform instead of a spectrogram. Defaults to True.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  xtransform = audiomentations.TimeStretch(\n",
        "    min_rate = min_rate,\n",
        "    max_rate = max_rate,\n",
        "    leave_length_unchanged = leave_length_unchanged,\n",
        "    p=1.0\n",
        "  )\n",
        "  self._audio_transform(df, xtransform, title=title, is_waveform=is_waveform)\n",
        "  return\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5SWv7o2hvmM"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_time_stretch(pluto.audio_control_dmajor, max_rate=5.4, is_waveform=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw7E0ohgx2E0"
      },
      "outputs": [],
      "source": [
        "# pluto.play_aug_time_stretch(pluto.df_music_data, max_rate=3.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0MZ_zi_x2Il"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_time_stretch(pluto.df_voice_data, max_rate=3.5, is_waveform=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcNZA9Kl9tMY"
      },
      "source": [
        "# Noise injection, add Gaussian noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgPOfP4g9tfg"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a {pluto_chapter_7}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def play_aug_noise_injection(self, df, min_amplitude=0.002,\n",
        "  max_amplitude=0.2,title='Gaussian noise injection',is_waveform=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Plays the audio data after applying Gaussian noise injection.\n",
        "\n",
        "  Args:\n",
        "      df (Union[str, List[Union[str, np.ndarray]]]): Name of the audio file or a list containing audio data, sampling rate, and file name.\n",
        "      min_amplitude (float): Minimum amplitude of noise. Defaults to 0.002.\n",
        "      max_amplitude (float): Maximum amplitude of noise. Defaults to 0.2.\n",
        "      title (str): Title of the plot. Defaults to 'Gaussian noise injection'.\n",
        "      is_waveform (bool): Whether to draw a waveform instead of a spectrogram. Defaults to True.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  xtransform = audiomentations.AddGaussianNoise(\n",
        "    min_amplitude = min_amplitude,\n",
        "    max_amplitude = max_amplitude,\n",
        "    p=1.0)\n",
        "  self._audio_transform(df, xtransform, title=title, is_waveform=is_waveform)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV7Fi5Rd9tir"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_noise_injection(pluto.audio_control_dmajor,\n",
        "  min_amplitude=0.02,max_amplitude=0.05,is_waveform=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFegcPlsVo5g"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_noise_injection(pluto.df_music_data,\n",
        "  min_amplitude=0.008,max_amplitude=0.05,is_waveform=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkLvL-KY7kbD"
      },
      "outputs": [],
      "source": [
        "pluto.play_aug_noise_injection(pluto.df_voice_data, max_amplitude=0.05, is_waveform=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('End of Chapter 8')"
      ],
      "metadata": {
        "id": "pu8utimvgVZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEj7fgaIN9_S"
      },
      "source": [
        "# Push up all changes (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXRf21BT9N8"
      },
      "source": [
        "- username: duchaba\n",
        "\n",
        "- password: [use the token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSXJKJFlOEeE"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJgBjC1Px5A"
      },
      "outputs": [],
      "source": [
        "# %%script false --no-raise-error  #temporary stop execute for export file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtZLtans4GCH"
      },
      "outputs": [],
      "source": [
        "# # compress/zip all the pluto generated images from this chapter for download\n",
        "# f = 'pluto-img-'+str(pluto.fname_id)+'.zip'\n",
        "# print(f)\n",
        "# !zip {f} /content/Data-Augmentation-with-Python/pluto_img/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO7lDYDWeLz"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iUPf3EWePd"
      },
      "source": [
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "✋ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- Pluto wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n",
        "- Use Xterm to debug cloud server\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRG3KaeWbGx"
      },
      "outputs": [],
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EzO7lDYDWeLz"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}