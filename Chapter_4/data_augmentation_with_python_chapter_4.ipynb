{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtnHR_uG0m7Z"
      },
      "source": [
        "# 🌻 Welcome to Chapter 4, Image Augmentation for Segmentation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I am glad to see you using this Python Notebook. 🐶\n",
        "\n",
        "The Python Notebook is an integral part of the book. You can add new “code cells” to extend the functions, add your data, and explore new possibilities, such as downloading additional real-world datasets from the Kaggle website and coding the **Fun challenges**. Furthermore, the book has **Fun facts**, in-depth discussion about augmentation techniques, and Pluto, an imaginary Siberian Huskey coding companion. Together they will guide you every steps of the way.\n",
        "\n",
        "Pluto encourages you to copy or save a copy of this Python Notebook to your local space and add the “text cells” to keep your notes. In other words, read the book and copy the relevant concept to this Python Notebook’s text-cells. Thus, you can have the explanation, note, original code, your code, and any crazy future ideas in one place.  \n",
        "\n",
        "\n",
        "💗 I hope you enjoy reading the book and hacking code as much as I enjoy writing it.\n",
        "\n",
        "\n",
        "## 🌟 Amazon Book\n",
        "\n",
        "---\n",
        "\n",
        "- The book is available on the Amazon Book website:\n",
        "  - https://www.amazon.com/dp/1803246456\n",
        "\n",
        "  - Author: Duc Haba\n",
        "  - Published: 2023\n",
        "  - Page count: 390+\n",
        "\n",
        "\n",
        "- The original Python Notebook is on:\n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/Chapter_4/data_augmentation_with_python_chapter_4.ipynb\n",
        "\n",
        "- 🚀 Click on the blue \"Open in Colab\" button at the top of this page to begin hacking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 😀 Excerpt from Chapter 4, Image Augmentation for Segmentation\n",
        "\n",
        "---\n",
        "\n",
        "> In case you haven’t bought the book. Here is an teaser from the first page of Chapter 4.\n",
        "\n",
        "---\n",
        "\n",
        "Image segmentation, like image classification, is the cornerstone in the computer vision domain. Image segmentation involves grouping parts of an image that belong to the same object, also known as pixel-level classification. Unlike image classification, which identifies and predicts the subject or label of a photo, image segmentation determines if a pixel belongs to a list of objects – for example, an urban photograph has streets, street signs, cars, trucks, bicycles, buildings, trees, and pedestrians. Image segmentation’s job is to decide if this image pixel belongs to a car, tree, or other objects.  \n",
        "\n",
        "Deep learning (DL), an artificial neural network (ANN) algorithm, has made a tremendous breakthrough in image segmentation. For example, image segmentation in DL makes it possible for autonomous vehicles and Advanced Driver Assistance Systems (ADASs) to detect navigable surfaces or pedestrians. Many medical applications use segmentation for tumor boundary drawing or measuring tissue volumes, for example.\n",
        "\n",
        "The image augmentation methods for segmentation or classification are the same, except segmentation comes with an additional mask image or ground-truth image. Therefore, most of what we learned about augmenting images for classification in Chapter 3 applies to augmenting segmentation.  \n",
        "\n",
        "This chapter aims to provide continuing geometric and photometric transformations for image segmentation. In particular, you will learn about the following topics:\n",
        "\n",
        "- Geometric and photometric transformations\n",
        "\n",
        "- Real-world segmentation datasets\n",
        "\n",
        "- Reinforce learning through Python code  \n",
        "\n",
        "\n",
        "Let’s begin with the geometric and photometric transformations for segmentation.\n",
        "\n",
        "---\n",
        "\n",
        "🌴 *end of excerpt from the book*"
      ],
      "metadata": {
        "id": "fQyQpZW1tRIv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psur6TottXJs"
      },
      "source": [
        "### GitHub Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-e-E23OC33r_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b477eafb-a276-40a1-ccc2-7bd3f6c2180c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.34.1\n"
          ]
        }
      ],
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kk-kUBgEnYzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bcd9af-4365-4078-9fb5-f5c03789871b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Data-Augmentation-with-Python'...\n",
            "remote: Enumerating objects: 454, done.\u001b[K\n",
            "remote: Counting objects: 100% (432/432), done.\u001b[K\n",
            "remote: Compressing objects: 100% (256/256), done.\u001b[K\n",
            "remote: Total 454 (delta 235), reused 353 (delta 175), pack-reused 22\u001b[K\n",
            "Receiving objects: 100% (454/454), 139.68 MiB | 19.57 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ],
      "source": [
        "url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktmuZO3xteG1"
      },
      "source": [
        "### Fetch file from URL (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ],
      "metadata": {
        "id": "wGPwtc1p9zQu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oObUsdZcj3Hk"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrz6ykdEj3RT"
      },
      "outputs": [],
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pluto"
      ],
      "metadata": {
        "id": "u9oQ-Do542nh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuljFGYftoyb"
      },
      "source": [
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq fastai\n",
        "!pip install albumentations\n",
        "!pip install opendatasets\n",
        "#\n",
        "# tested on the following version:\n",
        "# !pip install -Uqq fastai==2.6.3\n",
        "# !pip install albumentations==1.2.1"
      ],
      "metadata": {
        "id": "ZMXhhrwa-o7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e159a474-c1e0-43a9-e70e-4825bd24d452"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.2)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dDqYkFLYgSGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60623823-6637-48f2-dcd9-bfddedb42461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------- : ----------------------------\n",
            "            Hello from class : <class '__main__.PacktDataAug'> Class: PacktDataAug\n",
            "                   Code name : Pluto\n",
            "                   Author is : Duc Haba\n",
            "---------------------------- : ----------------------------\n",
            "\n",
            "fastai version (should be 2.6.3 or higher):  2.7.12\n",
            "---------------------------- : ----------------------------\n",
            "        albumentations 1.2.1 : actual 1.3.1\n",
            "---------------------------- : ----------------------------\n"
          ]
        }
      ],
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_3.py'\n",
        "%run {pluto_file}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqZKpMYA3YO1"
      },
      "source": [
        "- Double check on the server environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DFMl76ungbF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768b9c4b-bf37-4ea2-c351-31085ff831ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------- : ----------------------------\n",
            "                 System time : 2023/09/11 20:59\n",
            "                    Platform : linux\n",
            "     Pluto Version (Chapter) : 3.0\n",
            "             Python (3.7.10) : actual: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "            PyTorch (1.11.0) : actual: 2.0.1+cu118\n",
            "              Pandas (1.3.5) : actual: 1.5.3\n",
            "                 PIL (9.0.0) : actual: 9.4.0\n",
            "          Matplotlib (3.2.2) : actual: 3.7.1\n",
            "                   CPU count : 8\n",
            "                   CPU speed : 2.20 GHz\n",
            "               CPU max speed : 0.00 GHz\n",
            "---------------------------- : ----------------------------\n"
          ]
        }
      ],
      "source": [
        "pluto.say_sys_info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the ai doc\n",
        "help(pluto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbV7YNhqnx-H",
        "outputId": "1d73f723-d995-48bb-e347-47ce20299f60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on PacktDataAug in module __main__ object:\n",
            "\n",
            "class PacktDataAug(builtins.object)\n",
            " |  PacktDataAug(name='Pluto', is_verbose=True, *args, **kwargs)\n",
            " |  \n",
            " |  The PacktDataAug class is the based class for the\n",
            " |  \"Data Augmentation with Python\" book.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, name='Pluto', is_verbose=True, *args, **kwargs)\n",
            " |      This is the constructor function.\n",
            " |      \n",
            " |      Args:\n",
            " |      \n",
            " |       name (str): It requires a name for the object. The default is 'Pluto'\n",
            " |       verbose (bool):  The default value of `verbose` is True. This function prints out the\n",
            " |          name of the object if `is_verbose == True`. This is used to debug\n",
            " |          code. When you are ready to deploy the model, then you should set\n",
            " |          `is_verbose == False` in order to avoid printing out diagnostic\n",
            " |          messages.\n",
            " |      \n",
            " |        Additionally, this function takes any number of other\n",
            " |        parameters. These parameters are stored in `**kwargs` and are\n",
            " |        accessed via the function `get_kwargs()`. See the documentation\n",
            " |        for `get_kwargs()` for more details.\n",
            " |        Note that `__init__()` is\n",
            " |        automatically called when you create a new object.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None.\n",
            " |  \n",
            " |  build_sf_fname(self, df)\n",
            " |      This method builds the file name for a given row in the State Farm DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (Pandas DataFrame): The State Farm DataFrame.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  build_shoe_fname(self, start_path)\n",
            " |      This method builds the file name for a given directory.\n",
            " |      \n",
            " |      Args:\n",
            " |        start_path (str): The starting directory.\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: The DataFrame containing the file names.\n",
            " |  \n",
            " |  check_spelling(self, df, col_dest='description')\n",
            " |      This method checks the spelling in a column and returns a new column \n",
            " |      \"misspelled\" and \"misspelled_count\".\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        col_dest (str): The column name to be checked, default \"description\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  count_word(self, df, col_dest='description')\n",
            " |      This method counts the number of words in a column named \"wordc\"\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        col_dest (str): The column name to be counted, default \"description\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_augment_covid19(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the COVID-19 dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the COVID-19 dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the COVID-19 dataset.\n",
            " |  \n",
            " |  draw_augment_crowd(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Mall Crowd dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Mall Crowd dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Mall Crowd dataset.\n",
            " |  \n",
            " |  draw_augment_food(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Vietnam food dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Vietname food dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Vietnam food dataset.\n",
            " |  \n",
            " |  draw_augment_fungi(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Fungi dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Fungi dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Fungi dataset.\n",
            " |  \n",
            " |  draw_augment_people(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the People dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the People dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the People dataset.\n",
            " |  \n",
            " |  draw_augment_sea_animal(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Sea Animal dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Sea Animal dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Sea Animal dataset.\n",
            " |  \n",
            " |  draw_batch(self, df_filenames, disp_max=10, is_shuffle=False, figsize=(16, 8))\n",
            " |      This method draws the images specified in the DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        df_filenames (Pandas DataFrame): The DataFrame containing the file names.\n",
            " |        disp_max (int): The maximum number of images to be drawn. Default is 10.\n",
            " |        is_shuffle (bool): Whether to shuffle the images. Default is False.\n",
            " |        figsize (tuple): The figure size. Default is (16,8).\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_brightness(self, df, brightness=0.2, bsize=5)\n",
            " |      Draw an image and its brightness augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        brightness (float, optional): brightness multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_contrast(self, df, contrast=0.2, bsize=5)\n",
            " |      Draw an image and its contrast augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        contrast (float, optional): contrast multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_crop(self, df, bsize=15, pad_mode='zeros', isize=480)\n",
            " |      Draw an image and its cropped versions. It also augments the image dataset using crop and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |        isize (int, optional): image size. Defaults to 480.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_erasing(self, df, bsize=8, max_count=5)\n",
            " |      Draw an image and its erasing augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 8.\n",
            " |        max_count (int, optional): maximum number of times to erase an image. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_fancyPCA(self, df, alpha=0.1, bsize=5)\n",
            " |      Draw an image and its FancyPCA augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        alpha (float, optional): alpha value. Defaults to 0.1.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_flip(self, df, bsize=15)\n",
            " |      Draw an image and its horizontally flipped version. It also augments the image dataset using horizontal flip and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_flip_both(self, df, bsize=15, pad_mode='zeros')\n",
            " |      Draw an image and its both horizontally and vertically flipped versions.\n",
            " |      It also augments the image dataset using both horizontal and vertical flip and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_flip_pil(self, fname)\n",
            " |      Draw an image and its horizontal flipped version.\n",
            " |      \n",
            " |      Args:\n",
            " |        fname (str): path to the input image.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None.\n",
            " |  \n",
            " |  draw_image_grayscale(self, df, bsize=5)\n",
            " |      Draw an image and its grayscale versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_hue(self, df, hue=0.2, bsize=5)\n",
            " |      Draw an image and its hue augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        hue (float, optional): hue multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_noise(self, df, var_limit=(10.0, 50.0), bsize=5)\n",
            " |      Draw an image and its noise augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        var_limit (tuple, optional): noise variance range. Defaults to (10.0, 50.0).\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_rain(self, df, drop_length=20, drop_width=1, blur_value=1, bsize=2)\n",
            " |      Draw an image and its rain augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        drop_length (int, optional): drop length. Defaults to 20.\n",
            " |        drop_width (int, optional): drop width. Defaults to 1.\n",
            " |        blur_value (int, optional): blur value. Defaults to 1.\n",
            " |        bsize (int, optional): batch size. Defaults to 2.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_rotate(self, df, bsize=15, max_rotate=45.0, pad_mode='zeros')\n",
            " |      Draw an image and its rotated versions. It also augments the image dataset using rotation and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        max_rotate (float, optional): maximum rotation angle. Defaults to 45.0.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_saturation(self, df, saturation=0.2, bsize=5)\n",
            " |      Draw an image and its saturation augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        saturation (float, optional): saturation multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_sepia(self, df, bsize=5)\n",
            " |      Draw an image and its sepia augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_shift_pil(self, fname, x_axis, y_axis=0)\n",
            " |      Draw an image and its shifted versions using PIL library.\n",
            " |      \n",
            " |      Args:\n",
            " |        fname (str): filepath of the input image.\n",
            " |        x_axis (int): horizontal axis.\n",
            " |        y_axis (int, optional): vertical axis. Defaults to 0.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_sunflare(self, df, flare_roi=(0, 0, 1, 0.5), src_radius=400, bsize=2)\n",
            " |      Draw an image and its sunflare augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        flare_roi (tuple, optional): sunflare region of interest. Defaults to (0, 0, 1, 0.5).\n",
            " |        src_radius (int, optional): sunflare source radius. Defaults to 400.\n",
            " |        bsize (int, optional): batch size. Defaults to 2.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_brightness(self, df, brightness=0.2, label='Brightness')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        brightness (float): This is a float that will be used to adjust the brightness of the image.\n",
            " |          Default is 0.2.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"augment image\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_crop(self, df, label='Center Crop')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Center Crop\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_flip(self, df, label='Verticle Flip')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Vericle Flip\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_hue(self, df, label='Hue shifting')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Hue shifting\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_noise(self, df, label='Noice injection using Gaussian method')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Noice injection using Gaussian method\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_resize(self, df, label='Resize with squishing mode')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Center Crop\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_rotate(self, df, label='Rotate and Reflection Padding')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Rotate and Reflection Padding\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_warp(self, df, bsize=15, magnitude=0.2, pad_mode='zeros')\n",
            " |      Draw an image and its warped versions. It also augments the image dataset using warp and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        magnitude (float, optional): magnitude of warp. Defaults to 0.2.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_word_count(self, df, wc='wordc', is_stack_verticle=True)\n",
            " |      This method creates two plots:\n",
            " |        1. a boxplot of word count\n",
            " |        2. a histogram of word count\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        wc (str): The column name of word count, default \"wordc\".\n",
            " |        is_stack_verticle (bool): Whether to stack the two plots vertically. Default is True.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  fetch_df(self, csv, sep=',')\n",
            " |      This method reads and loads a CSV file into a Pandas DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        csv (str): The path to a CSV file.\n",
            " |        sep (str): The column separator character, default is comma \",\".\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: A pandas DataFrame.\n",
            " |  \n",
            " |  fetch_kaggle_comp_data(self, cname)\n",
            " |      This method downloads and unzip the data from the Competition on Kaggle.\n",
            " |      You need to join the competition before downloading the data.\n",
            " |      \n",
            " |      Args:\n",
            " |        cname (str): The name of the competition on Kaggle.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  fetch_kaggle_dataset(self, url, dest='kaggle')\n",
            " |      This method downloads the data from the Kaggle's dataset.\n",
            " |      You need NOT to join the competition before downloading the data.\n",
            " |      \n",
            " |      Args:\n",
            " |        url (str): The url of the dataset on Kaggle.\n",
            " |        dest (str): the destination path, default is \"kaggle\" directory.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  make_dir_dataframe(self, start_path)\n",
            " |      This method builds the file name for a given directory.\n",
            " |      \n",
            " |      Args:\n",
            " |        start_path (str): The starting directory.\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: The DataFrame containing the file names.\n",
            " |  \n",
            " |  print_batch_text(self, df_orig, disp_max=6, cols=['title', 'description'], is_larger_font=True)\n",
            " |      This method shows a batch of text data.\n",
            " |      \n",
            " |      Args:\n",
            " |        df_orig (DataFrame): The input DataFrame.\n",
            " |        disp_max (int): The maximum number of rows to be displayed. Default is 6.\n",
            " |        cols (list): The list of columns to display. Default is [\"title\", \"description\"].\n",
            " |        is_larger_font (bool): Whether to use larger font. Default is True.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  print_safe_parameters(self)\n",
            " |      Prints the safe parameters for the given data type.\n",
            " |      The safe parameters are the parameters that are likely to produce good results and do not cause overfitting.\n",
            " |      The function default dataset are following:\n",
            " |      \n",
            " |        * `Covid-19`: This is the data type for the COVID-19 dataset.\n",
            " |        * `People`: This is the data type for the People dataset.\n",
            " |        * `Fungi`: This is the data type for the Fungi dataset.\n",
            " |        * `Sea Animal`: This is the data type for the Sea Animal dataset.\n",
            " |        * `Food`: This is the data type for the Food dataset.\n",
            " |        * `Mall Crowd`: This is the data type for the Mall Crowd dataset.\n",
            " |      \n",
            " |      The table has two columns: `Filter` and `Parameter`.\n",
            " |      The `Filter` column lists the different filters that can be used,\n",
            " |      and the `Parameter` column lists the safe parameters for each filter.\n",
            " |      \n",
            " |      For example, the following is a sample table that is printed by the function for the `Covid-19` data type:\n",
            " |      \n",
            " |        | Filter              | Parameter |\n",
            " |        |---------------------|-----------|\n",
            " |        | Horizontal Flip     | Yes |\n",
            " |        | Vertical Flip       | Yes |\n",
            " |        | Croping and Padding | pad=border |\n",
            " |        | Rotation            | max_rotate=25.0 |\n",
            " |        | Warping             | magnitude=0.3 |\n",
            " |        | Lighting            | brightness=0.2 |\n",
            " |        | Grayscale           | Yes |\n",
            " |        | Contrast            | contrast=0.1 |\n",
            " |        | Saturation          | saturation=3.5 |\n",
            " |        | Hue Shifting        | hue=0.15 |\n",
            " |        | Noise Injection     | limit=(100.0, 300.0) |\n",
            " |        | Sun Flare           | NA |\n",
            " |        | Rain                | NA |\n",
            " |        | Sepia               | Yes |\n",
            " |        | FancyPCA            | alpha=0.5 |\n",
            " |        | Random Erasing      | max_count=3 |\n",
            " |  \n",
            " |  remember_kaggle_access_keys(self, username, key)\n",
            " |      This method takes a username and a Kaggle API key as arguments and stores\n",
            " |      them in the class object.\n",
            " |      \n",
            " |      Args:\n",
            " |       username (str): The Kaggle username.\n",
            " |       key (str): The Kaggle API key.\n",
            " |      \n",
            " |      Returns:\n",
            " |       None\n",
            " |  \n",
            " |  say_sys_info(self)\n",
            " |      Print out system information. Useful for\n",
            " |      debugging purposes. Prints out information such as\n",
            " |      the system time, platform, Python version, PyTorch\n",
            " |      version, Pandas version, PIL version, and\n",
            " |      Matplotlib version. Also prints the number of CPU\n",
            " |      cores and the CPU speed.\n",
            " |      \n",
            " |      Note that this function is added to the class `PacktDataAug` via\n",
            " |      the decorator `@add_method()`. This means that you can\n",
            " |      call this function as `p.say_system_info()`,\n",
            " |      where `p` is an instance of `PacktDAtaAug`.\n",
            " |      \n",
            " |      Args:\n",
            " |        None\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pluto_chapter_4 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_4.py'\n",
        "!cp {pluto_file} {pluto_chapter_4}"
      ],
      "metadata": {
        "id": "_zXvft_Cjb3k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat {pluto_file}"
      ],
      "metadata": {
        "id": "6cdLfXlF6ays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✋ STOP: Reinitalize Kaggle\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "- STOP: Update your Kaggle access username or key first."
      ],
      "metadata": {
        "id": "GEq5UZk-SDec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "\n",
        "!pip install pyspellchecker\n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"YOUR_KAGGLE_USERNAME\", \"YOUR_KAGGLE_API_KEY\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ],
      "metadata": {
        "id": "2VXY3ROiSNsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553b0682-c219-4545-faf2-350160cb5ed6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "\n",
            "required version 0.1.22 or higher:  0.1.22\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n",
            "\n",
            "Required version 0.7+ 0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf1ZN68a46on"
      },
      "source": [
        "# Fetch Kaggle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmuApvJnHbNu"
      },
      "source": [
        "## CamVid (Cambridge-Driving Labeled Video Database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RjQn8Y-FAUMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853604f9-5c19-4994-add6-ce124739f7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading camvid.zip to kaggle/camvid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 575M/575M [00:30<00:00, 20.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "url = 'https://www.kaggle.com/datasets/carlolepelaars/camvid'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove white space in directory and filename\n",
        "# run this until no error/output\n",
        "f = 'kaggle/camvid/CamVid/train'\n",
        "!find {f} -name \"* *\" -type d | rename 's/ /_/g'\n",
        "#!find {f} -name \"* *\" -type f | rename 's/ /_/g'"
      ],
      "metadata": {
        "id": "iwrgOj4-X75h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change method name to make_dir_dframe\n",
        "pluto.df_camvid = pluto.make_dir_dataframe(f)\n",
        "pluto.df_camvid.head(3)"
      ],
      "metadata": {
        "id": "m4w5JoK1Yd4G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f73e58c6-8325-471d-c167-ea8fde78a869"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          fname  label\n",
              "0   kaggle/camvid/CamVid/train/0016E5_05520.png  train\n",
              "1  kaggle/camvid/CamVid/train/0006R0_f02160.png  train\n",
              "2   kaggle/camvid/CamVid/train/0016E5_07620.png  train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-201aa172-2be3-45aa-9e5b-8f96e0f7296f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kaggle/camvid/CamVid/train/0016E5_05520.png</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kaggle/camvid/CamVid/train/0006R0_f02160.png</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kaggle/camvid/CamVid/train/0016E5_07620.png</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-201aa172-2be3-45aa-9e5b-8f96e0f7296f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-201aa172-2be3-45aa-9e5b-8f96e0f7296f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-201aa172-2be3-45aa-9e5b-8f96e0f7296f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b82f19a6-25f5-4ead-a7a7-ece674010ac8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b82f19a6-25f5-4ead-a7a7-ece674010ac8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b82f19a6-25f5-4ead-a7a7-ece674010ac8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "pluto.version = 4.0\n",
        "# prompt: write the documentation for the following function: _make_df_mask_name, make_df_mask_name\n",
        "@add_method(PacktDataAug)\n",
        "def _make_df_mask_name(self,fname):\n",
        "  \"\"\"\n",
        "  This function takes a file name as input and return the\n",
        "  corresponding mask file name.\n",
        "\n",
        "  Args:\n",
        "    fname: (str) File name of the image.\n",
        "\n",
        "  Returns:\n",
        "    mask_name: (str) Mask file name for corresponding image.\n",
        "  \"\"\"\n",
        "\n",
        "  p = pathlib.Path(fname)\n",
        "  return(f'{p.parent.parent}/{p.parent.name}_labels/{p.stem}_L{p.suffix}')\n",
        "#\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def make_df_mask_name(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  Adds a `mask_name` column to the `df` DataFrame.\n",
        "\n",
        "  This function is used to add a `mask_name` column to the DataFrame `df`. The\n",
        "  `mask_name` column is used to store the name of the mask associated with each\n",
        "  row in the DataFrame. The name of the mask is derived from the `fname` column\n",
        "  by removing the `.png` file extension from the value.\n",
        "\n",
        "  Args:\n",
        "    df: (dataframe) A pandas DataFrame with a `fname` column.\n",
        "\n",
        "  Returns:\n",
        "    The `df` DataFrame with a `mask_name` column.\n",
        "  \"\"\"\n",
        "\n",
        "  df['mask_name'] = df.fname.apply(self._make_df_mask_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "iRWrMh118U8I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write the documentation for the following function: _fetch_larger_font, print_batch_text\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_larger_font(self):\n",
        "\n",
        "  \"\"\"\n",
        "  This function returns the dataframe styles for larger font.\n",
        "\n",
        "  The function returns a dictionary that contains the styles for the heading\n",
        "  and cells in a dataframe. The headings are set to have a font size of 20px\n",
        "  and the cells are set to have a font size of 18px.\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    (dict) A dictionary containing the styles for the heading and cells in a dataframe.\n",
        "  \"\"\"\n",
        "\n",
        "  heading_properties = [('font-size', '20px')]\n",
        "  cell_properties = [('font-size', '18px')]\n",
        "  dfstyle = [dict(selector=\"th\", props=heading_properties),\n",
        "    dict(selector=\"td\", props=cell_properties)]\n",
        "  return dfstyle\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def print_batch_text(self,df_orig, disp_max=6, cols=[\"title\", \"description\"],is_larger_font=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Prints a batch of text from a DataFrame.\n",
        "\n",
        "  This function prints a batch of text from a DataFrame. The batch is specified\n",
        "  by the `disp_max` parameter, which is the maximum number of rows to print.\n",
        "  The `cols` parameter specifies the columns of text to print. The\n",
        "  `is_larger_font` parameter specifies whether to print the text in larger\n",
        "  font.\n",
        "\n",
        "  Args:\n",
        "    df_orig: (dataframe) The DataFrame containing the text to be printed.\n",
        "    disp_max: (int) The maximum number of rows to print. The default is 6.\n",
        "    cols: (list) The columns of text to print. The default is [\"title\", \"description]\n",
        "    is_larger_font: (bool) Whether to print the text in larger font.\n",
        "\n",
        "  Returns:\n",
        "    None.\n",
        "  \"\"\"\n",
        "\n",
        "  df = df_orig[cols]\n",
        "  with pandas.option_context(\"display.max_colwidth\", None):\n",
        "    if (is_larger_font):\n",
        "      display(df.sample(disp_max).style.set_table_styles(self._fetch_larger_font()))\n",
        "    else:\n",
        "      display(df.sample(disp_max))\n",
        "  return"
      ],
      "metadata": {
        "id": "V1tzcmaHaqfI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.make_df_mask_name(pluto.df_camvid)\n",
        "#pluto.df_camvid.head(3).style.set_table_styles(pluto._fetch_larger_font())"
      ],
      "metadata": {
        "id": "OrQBYKAz91bQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_camvid.head(3), disp_max=3, cols=['fname', 'mask_name'])"
      ],
      "metadata": {
        "id": "PBSEWittbPTW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "493700e0-f11c-4b3e-d4e6-6c34d98ac90d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7c9794743370>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9c633 th {\n",
              "  font-size: 20px;\n",
              "}\n",
              "#T_9c633 td {\n",
              "  font-size: 18px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9c633\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9c633_level0_col0\" class=\"col_heading level0 col0\" >fname</th>\n",
              "      <th id=\"T_9c633_level0_col1\" class=\"col_heading level0 col1\" >mask_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9c633_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_9c633_row0_col0\" class=\"data row0 col0\" >kaggle/camvid/CamVid/train/0016E5_05520.png</td>\n",
              "      <td id=\"T_9c633_row0_col1\" class=\"data row0 col1\" >kaggle/camvid/CamVid/train_labels/0016E5_05520_L.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c633_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
              "      <td id=\"T_9c633_row1_col0\" class=\"data row1 col0\" >kaggle/camvid/CamVid/train/0016E5_07620.png</td>\n",
              "      <td id=\"T_9c633_row1_col1\" class=\"data row1 col1\" >kaggle/camvid/CamVid/train_labels/0016E5_07620_L.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c633_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
              "      <td id=\"T_9c633_row2_col0\" class=\"data row2 col0\" >kaggle/camvid/CamVid/train/0006R0_f02160.png</td>\n",
              "      <td id=\"T_9c633_row2_col1\" class=\"data row2 col1\" >kaggle/camvid/CamVid/train_labels/0006R0_f02160_L.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pluto.draw_batch(pluto.df_camvid.fname, is_shuffle=True)"
      ],
      "metadata": {
        "id": "4xMdU2nfZhgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pluto.draw_batch(pluto.df_camvid.mask_name, is_shuffle=True)"
      ],
      "metadata": {
        "id": "AbJAPWs4B7qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write the documentation for the following function: _make_batch_seqmentation, draw_batch_segmentation\n",
        "@add_method(PacktDataAug)\n",
        "def _make_batch_segmentation(self,df, disp_max=8,is_shuffle=False):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame `df` and returns a list of file names and\n",
        "  corresponding mask file names.\n",
        "\n",
        "  Args:\n",
        "    df: (dataframe) The DataFrame to be processed.\n",
        "    disp_max: (int) The maximum number of rows to return.\n",
        "    is_shuffle: (bool) Whether to shuffle the DataFrame before returning the results.\n",
        "\n",
        "  Returns:\n",
        "    (list, list) A tuple of two lists. The first list contains the file names and\n",
        "    the second list contains the corresponding mask file names.\n",
        "  \"\"\"\n",
        "\n",
        "  # get random or not\n",
        "  if (is_shuffle):\n",
        "    _fns = df.sample(disp_max)\n",
        "    _fns.reset_index(drop=True, inplace=True)\n",
        "  else:\n",
        "    _fns = df.head(disp_max)\n",
        "\n",
        "  # merge the list\n",
        "  fname = []\n",
        "  fmask = []\n",
        "  for i in range(disp_max):\n",
        "    fname.append(str(_fns.fname[i]))\n",
        "    fname.append(str(_fns.mask_name[i]))\n",
        "    #\n",
        "    fmask.append(str(pathlib.Path(_fns.fname[i]).name))\n",
        "    fmask.append('Mask: ' +str(pathlib.Path(_fns.mask_name[i]).name))\n",
        "  #\n",
        "  return fname, fmask\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def draw_batch_segmentation(self,df, disp_max=8,is_shuffle=False, figsize=(16,8), disp_col=4):\n",
        "\n",
        "  \"\"\"\n",
        "  This function draws a batch of images from the specified DataFrame. The\n",
        "  number of images to be drawn is specified by the `disp_max` parameter. The\n",
        "  images can be either shuffled or drawn in order, as specified by the\n",
        "  `is_shuffle` parameter. The figure size can be specified using the\n",
        "  `figsize` parameter. The number of columns in the figure can be specified using\n",
        "  the `disp_col` parameter.\n",
        "\n",
        "  Args:\n",
        "      df: (dataframe) The DataFrame containing the images to be drawn.\n",
        "      disp_max: (int) The maximum number of images to be drawn. Default is 8.\n",
        "      is_shuffle: (bool) Whether to shuffle the images before drawing them.\n",
        "      Default is false\n",
        "      figsize: (tuple) The figure size in inches. Default is (16,8)\n",
        "      disp_col: (int) The number of columns in the figure. Default is 4.\n",
        "\n",
        "  **Returns:**\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  disp_row = int(numpy.round((disp_max/disp_col)+0.4, 0))\n",
        "  #\n",
        "  fname, fmask = self._make_batch_segmentation(df, disp_max,is_shuffle)\n",
        "  canvas, pic = matplotlib.pyplot.subplots(disp_row,disp_col, figsize=figsize)\n",
        "  #\n",
        "  _pics = pic.flatten()\n",
        "  # display it\n",
        "  for i, ax in enumerate(_pics):\n",
        "    try:\n",
        "      im = PIL.Image.open(fname[i])\n",
        "      ax.imshow(im)\n",
        "      ax.set_title(fmask[i])\n",
        "    except:\n",
        "      self._pp(\"Error, invalid image\", fname[i])\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ],
      "metadata": {
        "id": "h59VziyfcJXs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_batch_segmentation(pluto.df_camvid, is_shuffle=True)"
      ],
      "metadata": {
        "id": "G54EI5imB7tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic segmentation of aerial imagery"
      ],
      "metadata": {
        "id": "C1X2pxkiEAL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery'\n",
        "pluto.fetch_kaggle_dataset(url)"
      ],
      "metadata": {
        "id": "QyZBfjLJBlWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove white space in directory and filename\n",
        "# run this until no error/output\n",
        "f = 'kaggle/semantic-segmentation-of-aerial-imagery'\n",
        "!find {f} -name \"* *\" -type d | rename 's/ /_/g'\n",
        "#!find {f} -name \"* *\" -type f | rename 's/ /_/g'"
      ],
      "metadata": {
        "id": "qrSfIg7rTEhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove white space in directory and filename\n",
        "# run this until no error/output\n",
        "f = 'kaggle/semantic-segmentation-of-aerial-imagery'\n",
        "!find {f} -name \"* *\" -type d | rename 's/ /_/g'\n",
        "#!find {f} -name \"* *\" -type f | rename 's/ /_/g'"
      ],
      "metadata": {
        "id": "Hqiw6m-pTEkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm kaggle/semantic-segmentation-of-aerial-imagery/Semantic_segmentation_dataset/classes.json"
      ],
      "metadata": {
        "id": "XSRmoNuAqt7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_aerial = pluto.make_dir_dataframe(f)\n",
        "pluto.df_aerial.head()"
      ],
      "metadata": {
        "id": "GozytNUoTEoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_aerial.head(3), disp_max=3, cols=['fname', 'label'])"
      ],
      "metadata": {
        "id": "Gj6bLlaGcc1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: _make_df_mask_name_aerial and make_df_mask_name_aerial\n",
        "@add_method(PacktDataAug)\n",
        "def _make_df_mask_name_aerial(self,fname):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a file name and returns the corresponding mask file name.\n",
        "\n",
        "  The mask file name is the same as the image file name, except that it is\n",
        "  located in the `masks` directory.\n",
        "\n",
        "  Args:\n",
        "    fname: (str) The file name of the image.\n",
        "\n",
        "  Returns:\n",
        "    (str) The file name of the mask.\n",
        "  \"\"\"\n",
        "\n",
        "  p = pathlib.Path(fname)\n",
        "  return (f'{p.parent.parent}/masks/{p.stem}.png')\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def make_df_mask_name_aerial(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame and adds a new column called `mask_name`.\n",
        "\n",
        "  The `mask_name` column contains the file name of the mask for each image.\n",
        "\n",
        "  Args:\n",
        "    df: (dataframe) The DataFrame to be processed.\n",
        "\n",
        "  Returns:\n",
        "    (dataframe) The DataFrame with the new `mask_name` column.\n",
        "  \"\"\"\n",
        "\n",
        "  i = df[df['label'] =='masks'].index\n",
        "  df.drop(i, inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df['mask_name'] = df.fname.apply(self._make_df_mask_name_aerial)\n",
        "  return"
      ],
      "metadata": {
        "id": "sJRau4dSvndx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.make_df_mask_name_aerial(pluto.df_aerial)\n",
        "pluto.df_aerial.head(3)"
      ],
      "metadata": {
        "id": "eoR72wrCvt1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_aerial.head(3), disp_max=3, cols=['mask_name'])"
      ],
      "metadata": {
        "id": "UhYE3Pb2dNxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_batch_segmentation(pluto.df_aerial, is_shuffle=True)"
      ],
      "metadata": {
        "id": "hnxgAx6Evt4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometric transformations filters"
      ],
      "metadata": {
        "id": "smpQgFW0YR3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_flip_pil_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_flip_pil_segmen(self,fname):\n",
        "\n",
        "  \"\"\"\n",
        "  This function draws a horizontal flip of the image file `fname`.\n",
        "\n",
        "  Args:\n",
        "    fname: (str) The file name of the image.\n",
        "\n",
        "  Returns:\n",
        "    None.\n",
        "  \"\"\"\n",
        "\n",
        "  img = PIL.Image.open(fname)\n",
        "  mirror_img = PIL.ImageOps.mirror(img)\n",
        "  canvas, pic = matplotlib.pyplot.subplots(1,2, figsize=(16,6))\n",
        "  #display(img, mirror_img)\n",
        "  pic[0].imshow(img)\n",
        "  pic[0].set_title(pathlib.Path(fname).name)\n",
        "  pic[1].imshow(mirror_img)\n",
        "  pic[1].set_title('Horizontal Flip')\n",
        "  #\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ],
      "metadata": {
        "id": "nN2cRz4BtAIX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Horizontal flip"
      ],
      "metadata": {
        "id": "5pHBMc2YA6x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_pil_segmen(pluto.df_camvid.fname[0])"
      ],
      "metadata": {
        "id": "4esbEC_pAxwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_pil_segmen(pluto.df_camvid.mask_name[0])"
      ],
      "metadata": {
        "id": "O4MD67KdYAbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_pil_segmen(pluto.df_aerial.fname[0])"
      ],
      "metadata": {
        "id": "m-kq2R1T6xD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_pil_segmen(pluto.df_aerial.mask_name[0])"
      ],
      "metadata": {
        "id": "OKXWRI4Z6yA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function:  _draw_image_album_segmentation\n",
        "@add_method(PacktDataAug)\n",
        "def _draw_image_album_segmentation(self,df,aug_album,label_name):\n",
        "\n",
        "  \"\"\"\n",
        "  This function draws an image, its mask, and the output of an albumentation\n",
        "  operation on the image and mask.\n",
        "\n",
        "  Args:\n",
        "    df: (dataframe) The DataFrame containing the file paths of the images and\n",
        "      masks.\n",
        "    aug_album: (albumentations.Compose) The albumentations operation to be\n",
        "      applied to the image and mask.\n",
        "    label_name: (str) The name of the albumentation operation.\n",
        "\n",
        "  Returns:\n",
        "    None.\n",
        "    \"\"\"\n",
        "\n",
        "  bsize = 2\n",
        "  ncol = 4\n",
        "  nrow = 2\n",
        "  w = 18\n",
        "  h = 8\n",
        "  #\n",
        "  canvas, pic = matplotlib.pyplot.subplots(nrow, ncol, figsize=(w, h))\n",
        "  pics = pic.flatten()\n",
        "  # select random images\n",
        "  samp = df.sample(bsize)\n",
        "  samp.reset_index(drop=True, inplace=True)\n",
        "  #\n",
        "  _img = []\n",
        "  _label = []\n",
        "  for i in range(2):\n",
        "    img = PIL.Image.open(samp.fname[i])\n",
        "    imask = PIL.Image.open(samp.mask_name[i])\n",
        "    _img.append(img)\n",
        "    _img.append(imask)\n",
        "    img_numpy = numpy.array(img)\n",
        "    imask_numpy = numpy.array(imask)\n",
        "    album = aug_album(image=img_numpy,mask=imask_numpy)\n",
        "    _img.append(album['image'])\n",
        "    _img.append(album['mask'])\n",
        "    #\n",
        "    _label.append(str(pathlib.Path(samp.fname[i]).name))\n",
        "    _label.append('Mask:')\n",
        "    _label.append(label_name)\n",
        "    _label.append(label_name + ': Mask:')\n",
        "  #\n",
        "  for i, ax in enumerate(pics):\n",
        "    ax.imshow(_img[i])\n",
        "    ax.set_title(_label[i])\n",
        "  canvas.tight_layout()\n",
        "  self._drop_image(canvas)\n",
        "  canvas.show()\n",
        "  return"
      ],
      "metadata": {
        "id": "GmoJKM1i69Cu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function:  draw_image_flip_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_flip_segmen(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a horizontal flip on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.HorizontalFlip(p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Horizontal Flip')\n",
        "  return"
      ],
      "metadata": {
        "id": "rrF6AzsI0kl3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "BILiPNRh0kpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "Rgu3BtLo0ksZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertical and horizontal flip"
      ],
      "metadata": {
        "id": "UCDbWSenPyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_flip_both_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_flip_both_segmen(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a vertical and horizontal flip on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "      masks.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.Flip(p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Vertical Flip')\n",
        "  return"
      ],
      "metadata": {
        "id": "qqm3fGY70kvr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_both_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "IILw0ujR0kzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_flip_both_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "91d6bfCh0k1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rotating"
      ],
      "metadata": {
        "id": "ywT8RqkpSRUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# albumentations.Rotate?"
      ],
      "metadata": {
        "id": "nOvxU-M00k5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_rotate_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_rotate_segmen(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a rotate operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.Rotate(limit=45, p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Rotate')\n",
        "  return"
      ],
      "metadata": {
        "id": "Ys5tC12l0k8K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_rotate_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "-c0_lkdQ0k_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_rotate_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "cAV2D4580lCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Resize and Crop"
      ],
      "metadata": {
        "id": "0TOOFz2JwZmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_resize_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_resize_segmen(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a random resize and crop operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.RandomSizedCrop(min_max_height=(500, 600), height=500, width=500, p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Resize')\n",
        "  return"
      ],
      "metadata": {
        "id": "V8ladPvYq-lF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_resize_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "O61a4c93q-oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_resize_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "bh3dTqobq-r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transpose"
      ],
      "metadata": {
        "id": "2Rm1g2Udu-O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_transpose_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_transpose_segmen(self,df):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a transpose operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.Transpose(p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Transpose')\n",
        "  return"
      ],
      "metadata": {
        "id": "Pwx-dhuwu-b0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# albumentations.Transpose?"
      ],
      "metadata": {
        "id": "MEUxlH9bRU2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_transpose_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "zVU_3Bw-u-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_transpose_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "uQAnbS0kUSGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Photometric transformations"
      ],
      "metadata": {
        "id": "5adKElIq-6uF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lighting"
      ],
      "metadata": {
        "id": "Kpj6PEQDanJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_brightness_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_brightness_segmen(self,df,brightness=0.5):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a brightness operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "      brightness: (float) The brightness value. Default is 0.5.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.ColorJitter(brightness=brightness,\n",
        "    contrast=0.0, saturation=0.0,hue=0.0,always_apply=True, p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Brightness')\n",
        "  return"
      ],
      "metadata": {
        "id": "FyBKfRMuVlQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_brightness_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "xAJVZ4BgVlUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_brightness_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "tMq1aq2EVtLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrast"
      ],
      "metadata": {
        "id": "DCBhy4zOd-60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_contrast_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_contrast_segmen(self,df,contrast=0.5):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a contrast operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "      contrast: (float) The contrast value. Default is 0.5\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.ColorJitter(brightness=0.0,\n",
        "    contrast=contrast, saturation=0.0,hue=0.0,always_apply=True, p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Contrast')\n",
        "  return"
      ],
      "metadata": {
        "id": "GGoJeACLiDlJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_contrast_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "nHnvM8GMiDoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_contrast_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "dBKqQwMKiDrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FancyPCA"
      ],
      "metadata": {
        "id": "kgZdYdzk0VqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "# prompt: write detail Python documentation for the following function: draw_image_fancyPCA_segmen\n",
        "@add_method(PacktDataAug)\n",
        "def draw_image_fancyPCA_segmen(self,df,alpha=0.3):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a FancyPCA operation on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "      alpha: (float) The alpha value. Default is 0.3.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.FancyPCA(alpha=alpha, always_apply=True, p=1.0)\n",
        "  self._draw_image_album_segmentation(df,aug_album,'FancyPCA')\n",
        "  return"
      ],
      "metadata": {
        "id": "4c-PqTZUyq79"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_fancyPCA_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "O1Go4Ge8yq-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_image_fancyPCA_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "cnZN0JC40Ysi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combination"
      ],
      "metadata": {
        "id": "4OMdms3tO4V6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## draw table"
      ],
      "metadata": {
        "id": "pTm8mMAkO-YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_safe_parameters_segmen(self):\n",
        "\n",
        "  \"\"\"\n",
        "  Prints a table of the augmentation parameters that are safe to use on the CamVid and Aerial datasets.\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  data = [\n",
        "    ['Horizontal Flip','Yes','Yes','Yes','Yes'],\n",
        "    ['Vertical Flip','Yes','Yes','Yes','Yes'],\n",
        "    ['Resize and Crop','Yes','Yes','Yes','Yes'],\n",
        "    ['Rotation','Yes','Yes','Yes','Yes'],\n",
        "    ['Transpose','Yes','Yes','Yes','Yes'],\n",
        "    ['Lighting','Yes','No','Yes','No'],\n",
        "    ['FancyPCA','Yes','No','Yes','No']]\n",
        "  # Create the pandas DataFrame\n",
        "  df = pandas.DataFrame(data, columns=['filters','CamVid','CamVid Mask', 'Aerial', 'Aerial Mask'])\n",
        "  display(df)\n",
        "  return"
      ],
      "metadata": {
        "id": "Rr_qx52jPJ83"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_safe_parameters_segmen()"
      ],
      "metadata": {
        "id": "W8t4oN04PKAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## draw segmentation"
      ],
      "metadata": {
        "id": "6wTmkF7Slmzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_4}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def draw_uber_segmen(self,df,contrast=0.5):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame of images and masks and draws the images,\n",
        "  their masks, and the output of a combination of augmentations on the images and masks.\n",
        "\n",
        "  Args:\n",
        "      df: (DataFrame) The DataFrame containing the file paths of the images and\n",
        "        masks.\n",
        "      contrast: (float) The contrast value. Default is 0.5.\n",
        "\n",
        "  Returns:\n",
        "      None.\n",
        "  \"\"\"\n",
        "\n",
        "  aug_album = albumentations.Compose([\n",
        "    albumentations.ColorJitter(brightness=0.5,contrast=0.0, saturation=0.0,hue=0.0,p=0.5),\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.Flip(p=0.5),\n",
        "    albumentations.Rotate(limit=45, p=0.5),\n",
        "    albumentations.RandomSizedCrop(min_max_height=(500, 600), height=500, width=500,p=0.5),\n",
        "    albumentations.Transpose(p=0.5),\n",
        "    albumentations.FancyPCA(alpha=0.2, p=0.5)\n",
        "  ])\n",
        "  self._draw_image_album_segmentation(df,aug_album,'Combine')\n",
        "  return"
      ],
      "metadata": {
        "id": "w8ykI6QJp4_4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_uber_segmen(pluto.df_camvid)"
      ],
      "metadata": {
        "id": "ntleGJ6-SnuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_uber_segmen(pluto.df_aerial)"
      ],
      "metadata": {
        "id": "KKRfq8-YWm3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out all the AI generated doc.\n",
        "help(pluto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UhlMqGBSdIb",
        "outputId": "a99a5585-cb77-4f67-8e46-40e97a8c3936"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on PacktDataAug in module __main__ object:\n",
            "\n",
            "class PacktDataAug(builtins.object)\n",
            " |  PacktDataAug(name='Pluto', is_verbose=True, *args, **kwargs)\n",
            " |  \n",
            " |  The PacktDataAug class is the based class for the\n",
            " |  \"Data Augmentation with Python\" book.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, name='Pluto', is_verbose=True, *args, **kwargs)\n",
            " |      This is the constructor function.\n",
            " |      \n",
            " |      Args:\n",
            " |      \n",
            " |       name (str): It requires a name for the object. The default is 'Pluto'\n",
            " |       verbose (bool):  The default value of `verbose` is True. This function prints out the\n",
            " |          name of the object if `is_verbose == True`. This is used to debug\n",
            " |          code. When you are ready to deploy the model, then you should set\n",
            " |          `is_verbose == False` in order to avoid printing out diagnostic\n",
            " |          messages.\n",
            " |      \n",
            " |        Additionally, this function takes any number of other\n",
            " |        parameters. These parameters are stored in `**kwargs` and are\n",
            " |        accessed via the function `get_kwargs()`. See the documentation\n",
            " |        for `get_kwargs()` for more details.\n",
            " |        Note that `__init__()` is\n",
            " |        automatically called when you create a new object.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None.\n",
            " |  \n",
            " |  build_sf_fname(self, df)\n",
            " |      This method builds the file name for a given row in the State Farm DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (Pandas DataFrame): The State Farm DataFrame.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  build_shoe_fname(self, start_path)\n",
            " |      This method builds the file name for a given directory.\n",
            " |      \n",
            " |      Args:\n",
            " |        start_path (str): The starting directory.\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: The DataFrame containing the file names.\n",
            " |  \n",
            " |  check_spelling(self, df, col_dest='description')\n",
            " |      This method checks the spelling in a column and returns a new column \n",
            " |      \"misspelled\" and \"misspelled_count\".\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        col_dest (str): The column name to be checked, default \"description\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  count_word(self, df, col_dest='description')\n",
            " |      This method counts the number of words in a column named \"wordc\"\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        col_dest (str): The column name to be counted, default \"description\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_augment_covid19(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the COVID-19 dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the COVID-19 dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the COVID-19 dataset.\n",
            " |  \n",
            " |  draw_augment_crowd(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Mall Crowd dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Mall Crowd dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Mall Crowd dataset.\n",
            " |  \n",
            " |  draw_augment_food(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Vietnam food dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Vietname food dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Vietnam food dataset.\n",
            " |  \n",
            " |  draw_augment_fungi(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Fungi dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Fungi dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Fungi dataset.\n",
            " |  \n",
            " |  draw_augment_people(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the People dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the People dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the People dataset.\n",
            " |  \n",
            " |  draw_augment_sea_animal(self, df, bsize=15)\n",
            " |      This function is used to draw the data loader for the Sea Animal dataset.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the Sea Animal dataset.\n",
            " |        bsize (int): This is the batch size for the data loader. Default is 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.data.DataLoader: returns a data loader for the Sea Animal dataset.\n",
            " |  \n",
            " |  draw_batch(self, df_filenames, disp_max=10, is_shuffle=False, figsize=(16, 8))\n",
            " |      This method draws the images specified in the DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        df_filenames (Pandas DataFrame): The DataFrame containing the file names.\n",
            " |        disp_max (int): The maximum number of images to be drawn. Default is 10.\n",
            " |        is_shuffle (bool): Whether to shuffle the images. Default is False.\n",
            " |        figsize (tuple): The figure size. Default is (16,8).\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_batch_segmentation(self, df, disp_max=8, is_shuffle=False, figsize=(16, 8), disp_col=4)\n",
            " |  \n",
            " |  draw_image_brightness(self, df, brightness=0.2, bsize=5)\n",
            " |      Draw an image and its brightness augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        brightness (float, optional): brightness multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_contrast(self, df, contrast=0.2, bsize=5)\n",
            " |      Draw an image and its contrast augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        contrast (float, optional): contrast multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_contrast_segmen(self, df, contrast=0.5)\n",
            " |  \n",
            " |  draw_image_crop(self, df, bsize=15, pad_mode='zeros', isize=480)\n",
            " |      Draw an image and its cropped versions. It also augments the image dataset using crop and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |        isize (int, optional): image size. Defaults to 480.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_erasing(self, df, bsize=8, max_count=5)\n",
            " |      Draw an image and its erasing augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 8.\n",
            " |        max_count (int, optional): maximum number of times to erase an image. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_fancyPCA(self, df, alpha=0.1, bsize=5)\n",
            " |      Draw an image and its FancyPCA augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        alpha (float, optional): alpha value. Defaults to 0.1.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_fancyPCA_segmen(self, df, alpha=0.3)\n",
            " |  \n",
            " |  draw_image_flip(self, df, bsize=15)\n",
            " |      Draw an image and its horizontally flipped version. It also augments the image dataset using horizontal flip and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_flip_both(self, df, bsize=15, pad_mode='zeros')\n",
            " |      Draw an image and its both horizontally and vertically flipped versions.\n",
            " |      It also augments the image dataset using both horizontal and vertical flip and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_flip_both_segmen(self, df)\n",
            " |  \n",
            " |  draw_image_flip_pil(self, fname)\n",
            " |      Draw an image and its horizontal flipped version.\n",
            " |      \n",
            " |      Args:\n",
            " |        fname (str): path to the input image.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None.\n",
            " |  \n",
            " |  draw_image_flip_pil_segmen(self, fname)\n",
            " |  \n",
            " |  draw_image_flip_segmen(self, df)\n",
            " |  \n",
            " |  draw_image_grayscale(self, df, bsize=5)\n",
            " |      Draw an image and its grayscale versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_hue(self, df, hue=0.2, bsize=5)\n",
            " |      Draw an image and its hue augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        hue (float, optional): hue multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_noise(self, df, var_limit=(10.0, 50.0), bsize=5)\n",
            " |      Draw an image and its noise augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        var_limit (tuple, optional): noise variance range. Defaults to (10.0, 50.0).\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_rain(self, df, drop_length=20, drop_width=1, blur_value=1, bsize=2)\n",
            " |      Draw an image and its rain augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        drop_length (int, optional): drop length. Defaults to 20.\n",
            " |        drop_width (int, optional): drop width. Defaults to 1.\n",
            " |        blur_value (int, optional): blur value. Defaults to 1.\n",
            " |        bsize (int, optional): batch size. Defaults to 2.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_resize_segmen(self, df)\n",
            " |  \n",
            " |  draw_image_rotate(self, df, bsize=15, max_rotate=45.0, pad_mode='zeros')\n",
            " |      Draw an image and its rotated versions. It also augments the image dataset using rotation and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        max_rotate (float, optional): maximum rotation angle. Defaults to 45.0.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_image_rotate_segmen(self, df)\n",
            " |  \n",
            " |  draw_image_saturation(self, df, saturation=0.2, bsize=5)\n",
            " |      Draw an image and its saturation augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        saturation (float, optional): saturation multiplier. Defaults to 0.2.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_sepia(self, df, bsize=5)\n",
            " |      Draw an image and its sepia augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 5.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_shift_pil(self, fname, x_axis, y_axis=0)\n",
            " |      Draw an image and its shifted versions using PIL library.\n",
            " |      \n",
            " |      Args:\n",
            " |        fname (str): filepath of the input image.\n",
            " |        x_axis (int): horizontal axis.\n",
            " |        y_axis (int, optional): vertical axis. Defaults to 0.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_sunflare(self, df, flare_roi=(0, 0, 1, 0.5), src_radius=400, bsize=2)\n",
            " |      Draw an image and its sunflare augmented versions using albumentations to do image transformation\n",
            " |      and display it in batch.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        flare_roi (tuple, optional): sunflare region of interest. Defaults to (0, 0, 1, 0.5).\n",
            " |        src_radius (int, optional): sunflare source radius. Defaults to 400.\n",
            " |        bsize (int, optional): batch size. Defaults to 2.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_brightness(self, df, brightness=0.2, label='Brightness')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        brightness (float): This is a float that will be used to adjust the brightness of the image.\n",
            " |          Default is 0.2.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"augment image\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_crop(self, df, label='Center Crop')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Center Crop\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_flip(self, df, label='Verticle Flip')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Vericle Flip\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_hue(self, df, label='Hue shifting')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Hue shifting\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_noise(self, df, label='Noice injection using Gaussian method')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Noice injection using Gaussian method\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_resize(self, df, label='Resize with squishing mode')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Center Crop\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_teaser_rotate(self, df, label='Rotate and Reflection Padding')\n",
            " |      This function is used to draw the image teaser for the book.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): This is a pandas DataFrame that contains the data for the dataset.\n",
            " |        label (str): This is a string that will be used to label the image that has been augmented.\n",
            " |          Default is \"Rotate and Reflection Padding\"\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  draw_image_transpose_segmen(self, df)\n",
            " |      This function takes a DataFrame of images and masks and draws the images,\n",
            " |      their masks, and the output of a transpose operation on the images and masks.\n",
            " |      \n",
            " |      Args:\n",
            " |          df: (DataFrame) The DataFrame containing the file paths of the images and\n",
            " |            masks.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None.\n",
            " |  \n",
            " |  draw_image_warp(self, df, bsize=15, magnitude=0.2, pad_mode='zeros')\n",
            " |      Draw an image and its warped versions. It also augments the image dataset using warp and resize.\n",
            " |      \n",
            " |      Args:\n",
            " |        df (pandas.DataFrame): input dataframe.\n",
            " |        bsize (int, optional): batch size. Defaults to 15.\n",
            " |        magnitude (float, optional): magnitude of warp. Defaults to 0.2.\n",
            " |        pad_mode (str, optional): padding mode. Defaults to 'zeros'.\n",
            " |      \n",
            " |      Returns:\n",
            " |        fastai.vision.data.ImageDataLoaders: dataloader object\n",
            " |  \n",
            " |  draw_uber_segmen(self, df, contrast=0.5)\n",
            " |  \n",
            " |  draw_word_count(self, df, wc='wordc', is_stack_verticle=True)\n",
            " |      This method creates two plots:\n",
            " |        1. a boxplot of word count\n",
            " |        2. a histogram of word count\n",
            " |      \n",
            " |      Args:\n",
            " |        df (DataFrame): The input DataFrame.\n",
            " |        wc (str): The column name of word count, default \"wordc\".\n",
            " |        is_stack_verticle (bool): Whether to stack the two plots vertically. Default is True.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  fetch_df(self, csv, sep=',')\n",
            " |      This method reads and loads a CSV file into a Pandas DataFrame.\n",
            " |      \n",
            " |      Args:\n",
            " |        csv (str): The path to a CSV file.\n",
            " |        sep (str): The column separator character, default is comma \",\".\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: A pandas DataFrame.\n",
            " |  \n",
            " |  fetch_kaggle_comp_data(self, cname)\n",
            " |  \n",
            " |  fetch_kaggle_dataset(self, url, dest='kaggle')\n",
            " |  \n",
            " |  make_df_mask_name(self, df)\n",
            " |      Adds a `mask_name` column to the `df` DataFrame.\n",
            " |      \n",
            " |      This function is used to add a `mask_name` column to the DataFrame `df`. The\n",
            " |      `mask_name` column is used to store the name of the mask associated with each\n",
            " |      row in the DataFrame. The name of the mask is derived from the `fname` column\n",
            " |      by removing the `.png` file extension from the value.\n",
            " |      \n",
            " |      Args:\n",
            " |        df: (dataframe) A pandas DataFrame with a `fname` column.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The `df` DataFrame with a `mask_name` column.\n",
            " |  \n",
            " |  make_df_mask_name_aerial(self, df)\n",
            " |  \n",
            " |  make_dir_dataframe(self, start_path)\n",
            " |      This method builds the file name for a given directory.\n",
            " |      \n",
            " |      Args:\n",
            " |        start_path (str): The starting directory.\n",
            " |      \n",
            " |      Returns:\n",
            " |        DataFrame: The DataFrame containing the file names.\n",
            " |  \n",
            " |  print_batch_text(self, df_orig, disp_max=6, cols=['title', 'description'], is_larger_font=True)\n",
            " |      Prints a batch of text from a DataFrame.\n",
            " |      \n",
            " |      This function prints a batch of text from a DataFrame. The batch is specified\n",
            " |      by the `disp_max` parameter, which is the maximum number of rows to print.\n",
            " |      The `cols` parameter specifies the columns of text to print. The\n",
            " |      `is_larger_font` parameter specifies whether to print the text in larger\n",
            " |      font.\n",
            " |      \n",
            " |      Args:\n",
            " |        df_orig: (dataframe) The DataFrame containing the text to be printed.\n",
            " |        disp_max: (int) The maximum number of rows to print. The default is 6.\n",
            " |        cols: (list) The columns of text to print. The default is [\"title\", \"description]\n",
            " |        is_larger_font: (bool) Whether to print the text in larger font.\n",
            " |      \n",
            " |      Returns:\n",
            " |        None.\n",
            " |  \n",
            " |  print_safe_parameters(self)\n",
            " |      Prints the safe parameters for the given data type.\n",
            " |      The safe parameters are the parameters that are likely to produce good results and do not cause overfitting.\n",
            " |      The function default dataset are following:\n",
            " |      \n",
            " |        * `Covid-19`: This is the data type for the COVID-19 dataset.\n",
            " |        * `People`: This is the data type for the People dataset.\n",
            " |        * `Fungi`: This is the data type for the Fungi dataset.\n",
            " |        * `Sea Animal`: This is the data type for the Sea Animal dataset.\n",
            " |        * `Food`: This is the data type for the Food dataset.\n",
            " |        * `Mall Crowd`: This is the data type for the Mall Crowd dataset.\n",
            " |      \n",
            " |      The table has two columns: `Filter` and `Parameter`.\n",
            " |      The `Filter` column lists the different filters that can be used,\n",
            " |      and the `Parameter` column lists the safe parameters for each filter.\n",
            " |      \n",
            " |      For example, the following is a sample table that is printed by the function for the `Covid-19` data type:\n",
            " |      \n",
            " |        | Filter              | Parameter |\n",
            " |        |---------------------|-----------|\n",
            " |        | Horizontal Flip     | Yes |\n",
            " |        | Vertical Flip       | Yes |\n",
            " |        | Croping and Padding | pad=border |\n",
            " |        | Rotation            | max_rotate=25.0 |\n",
            " |        | Warping             | magnitude=0.3 |\n",
            " |        | Lighting            | brightness=0.2 |\n",
            " |        | Grayscale           | Yes |\n",
            " |        | Contrast            | contrast=0.1 |\n",
            " |        | Saturation          | saturation=3.5 |\n",
            " |        | Hue Shifting        | hue=0.15 |\n",
            " |        | Noise Injection     | limit=(100.0, 300.0) |\n",
            " |        | Sun Flare           | NA |\n",
            " |        | Rain                | NA |\n",
            " |        | Sepia               | Yes |\n",
            " |        | FancyPCA            | alpha=0.5 |\n",
            " |        | Random Erasing      | max_count=3 |\n",
            " |  \n",
            " |  print_safe_parameters_segmen(self)\n",
            " |  \n",
            " |  remember_kaggle_access_keys(self, username, key)\n",
            " |      This method takes a username and a Kaggle API key as arguments and stores\n",
            " |      them in the class object.\n",
            " |      \n",
            " |      Args:\n",
            " |       username (str): The Kaggle username.\n",
            " |       key (str): The Kaggle API key.\n",
            " |      \n",
            " |      Returns:\n",
            " |       None\n",
            " |  \n",
            " |  say_sys_info(self)\n",
            " |      Print out system information. Useful for\n",
            " |      debugging purposes. Prints out information such as\n",
            " |      the system time, platform, Python version, PyTorch\n",
            " |      version, Pandas version, PIL version, and\n",
            " |      Matplotlib version. Also prints the number of CPU\n",
            " |      cores and the CPU speed.\n",
            " |      \n",
            " |      Note that this function is added to the class `PacktDataAug` via\n",
            " |      the decorator `@add_method()`. This means that you can\n",
            " |      call this function as `p.say_system_info()`,\n",
            " |      where `p` is an instance of `PacktDAtaAug`.\n",
            " |      \n",
            " |      Args:\n",
            " |        None\n",
            " |      \n",
            " |      Returns:\n",
            " |        None\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# end of chapter 4\n",
        "print('End of chapter 4.')"
      ],
      "metadata": {
        "id": "87VP_baYX5ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push up all changes (Optional)"
      ],
      "metadata": {
        "id": "LEj7fgaIN9_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- username: [your username]\n",
        "\n",
        "- password: [use the token]"
      ],
      "metadata": {
        "id": "lHXRf21BT9N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"fixed minor indent error in pluto_chapter_3.py\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ],
      "metadata": {
        "id": "eSXJKJFlOEeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c012ba-3df5-4f2e-e700-e8125a4751c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 73b2193] fixed minor indent error in pluto_chapter_3.py\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.colab\n",
        "# import datetime\n",
        "# @add_method(PacktDataAug)\n",
        "# def zip_download(self,dname='/content/Data-Augmentation-with-Python/pluto_img'):\n",
        "#   d = datetime.datetime.now()\n",
        "#   d = d.strftime('%Y%m%d_')\n",
        "#   fname = f'img{d}{self.fname_id}.zip'\n",
        "#   !zip {fname} {dname}/*\n",
        "#   google.colab.files.download(fname)\n",
        "#   return"
      ],
      "metadata": {
        "id": "unPfU8_5vZdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pluto.zip_download()"
      ],
      "metadata": {
        "id": "VrACmFh6va0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO7lDYDWeLz"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2iUPf3EWePd"
      },
      "source": [
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "✋ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- Pluto wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n",
        "- Use Xterm to debug cloud server\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ],
      "metadata": {
        "id": "vXRG3KaeWbGx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyO5ZePgY6NqbUrLsTwVc1fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}