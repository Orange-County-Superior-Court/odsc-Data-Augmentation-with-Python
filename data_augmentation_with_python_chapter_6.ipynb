{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation with Python, Chapter 6"
      ],
      "metadata": {
        "id": "SIt9Tm6eXARu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🌻 Welcome to Chapter 6, \"Text Augmentation with Machine Learning\"\n",
        "\n",
        "In this chapter, you will learn:\n",
        "\n",
        "- Machine Learning models \n",
        "\n",
        "- Word augmenting \n",
        "\n",
        "- Sentence augmenting \n",
        "\n",
        "- Real-world NLP datasets \n",
        "\n",
        "- Reinforce learning through Python code "
      ],
      "metadata": {
        "id": "1DlWAB8G4ijz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Notebook"
      ],
      "metadata": {
        "id": "ZZ8-JIXv6jmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This Notebook original link is: \n",
        "  - https://github.com/PacktPublishing/Data-Augmentation-with-Python/blob/main/data_augmentation_with_python_chapter_6.ipynb"
      ],
      "metadata": {
        "id": "hZhktqct6ZTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Clone"
      ],
      "metadata": {
        "id": "4b52gSlp60SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==4.2.0\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "# version4.2.0"
      ],
      "metadata": {
        "id": "XIngCjpIiy9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# git version should be 2.17.1 or higher\n",
        "!git --version"
      ],
      "metadata": {
        "id": "6oeDAu1u6zWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/PacktPublishing/Data-Augmentation-with-Python'\n",
        "!git clone {url}"
      ],
      "metadata": {
        "id": "J9buwUR767Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch file from URL (Optional)\n",
        "\n",
        "- Uncommend the below 2 code cells if you want to use URL and not Git Clone"
      ],
      "metadata": {
        "id": "lOawA01L7Ok0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# #\n",
        "# def fetch_file(url, dst):\n",
        "#   downloaded_obj = requests.get(url)\n",
        "#   with open(dst, \"wb\") as file:\n",
        "#     file.write(downloaded_obj.content)\n",
        "#   return"
      ],
      "metadata": {
        "id": "HsmQ7rgj67Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url = ''\n",
        "# dst = 'pluto_chapter_1.py'\n",
        "# fetch_file(url,dst)"
      ],
      "metadata": {
        "id": "_nKp0nxT67aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Pluto\n",
        "\n",
        "- Instantiate up Pluto, aka. \"Pluto, wake up!\""
      ],
      "metadata": {
        "id": "6462KTtr7cFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% CARRY-OVER code install\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "!pip install pyspellchecker \n",
        "!pip install missingno\n",
        "!pip install nltk\n",
        "!pip install wordcloud\n",
        "!pip install filter-profanity\n",
        "!pip install nlpaug"
      ],
      "metadata": {
        "id": "P10V_4JQ7DEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load and run the pluto chapter 1 Python code.\n",
        "pluto_file = 'Data-Augmentation-with-Python/pluto/pluto_chapter_5.py'\n",
        "%run {pluto_file}"
      ],
      "metadata": {
        "id": "u3zbkOO86_WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Pluto"
      ],
      "metadata": {
        "id": "yhRR0JSf746h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.say_sys_info()"
      ],
      "metadata": {
        "id": "nBIw7fiI6_Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Export to .py"
      ],
      "metadata": {
        "id": "7jduoUhMCN3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto_chapter_6 = 'Data-Augmentation-with-Python/pluto/pluto_chapter_6.py'\n",
        "!cp {pluto_file} {pluto_chapter_6}"
      ],
      "metadata": {
        "id": "Gfx9Ai5Opyqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✋ Get Kaggle username and api key (Optional for this chapter)\n",
        "\n",
        "- Install the following libraries, and import it on the Notebook.\n",
        "- Follow by initialize Kaggle username, key and fetch methods.\n",
        "- STOP: Update your Kaggle access username or key first."
      ],
      "metadata": {
        "id": "kQ6ap39x8HyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- : --------------------\n",
        "# READ ME\n",
        "# Chapter 2 begin:\n",
        "# Install the following libraries, and import it on the Notebook.\n",
        "# Follow by initialize Kaggle username, key and fetch methods.\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "# -------------------- : --------------------\n",
        "\n",
        "!pip install opendatasets --upgrade\n",
        "import opendatasets\n",
        "print(\"\\nrequired version 0.1.22 or higher: \", opendatasets.__version__)\n",
        "\n",
        "!pip install pyspellchecker \n",
        "import spellchecker\n",
        "print(\"\\nRequired version 0.7+\", spellchecker.__version__)\n",
        "\n",
        "# STOP: Update your Kaggle access username or key first.\n",
        "pluto.remember_kaggle_access_keys(\"YOUR-USERNAME\", \"YOUR-KEY\")\n",
        "pluto._write_kaggle_credit()\n",
        "import kaggle\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_comp_data(self,cname):\n",
        "  #self._write_kaggle_credit()  # need to run only once.\n",
        "  path = pathlib.Path(cname)\n",
        "  kaggle.api.competition_download_cli(str(path))\n",
        "  zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
        "  return\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def fetch_kaggle_dataset(self,url,dest=\"kaggle\"):\n",
        "  #self._write_kaggle_credit()    # need to run only once.\n",
        "  opendatasets.download(url,data_dir=dest)\n",
        "  return\n",
        "# -------------------- : --------------------\n"
      ],
      "metadata": {
        "id": "sf4Obdp-77CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch data from chapter 5"
      ],
      "metadata": {
        "id": "gFAQHzXjYvr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data'\n",
        "!ls -la {f}"
      ],
      "metadata": {
        "id": "j-fk5IEEyfUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/netflix_data.csv'\n",
        "pluto.df_netflix_data = pluto.fetch_df(f,sep='~')"
      ],
      "metadata": {
        "id": "Asm98OsWXcvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'Data-Augmentation-with-Python/pluto_data/twitter_data.csv'\n",
        "pluto.df_twitter_data = pluto.fetch_df(f,sep='~')"
      ],
      "metadata": {
        "id": "5Xt1GrQXat_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_batch_text(pluto.df_netflix_data, cols=['title','description'])"
      ],
      "metadata": {
        "id": "Se_a_tFhXcyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_netflix_data.description, \n",
        "  xignore_words=wordcloud.STOPWORDS, \n",
        "  title='Word Cloud: Netflix Movie Review')"
      ],
      "metadata": {
        "id": "9quCB-ddXc1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.draw_text_wordcloud(pluto.df_twitter_data.clean_tweet, \n",
        "  xignore_words=wordcloud.STOPWORDS, \n",
        "  title='Word Cloud: Twitter Tweets')"
      ],
      "metadata": {
        "id": "dWE1Gwb4Xc4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extened control text"
      ],
      "metadata": {
        "id": "YodrXsBjVH62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "pluto.version = 7.0\n",
        "#\n",
        "pluto.orig_text = '''It was the best of times. It was the worst of times. It was the age of wisdom. It was the age of foolishness. It was the epoch of belief. It was the epoch of incredulity.'''\n",
        "pluto.orig_dickens_page = '''There were a king with a large jaw and a queen with a plain face, \n",
        "on the throne of England; there were a king with a large jaw and a queen with a fair face, on the throne of France. \n",
        "In both countries it was clearer than crystal to the lords of the State preserves of loaves and fishes, \n",
        "that things in general were settled for ever.\n",
        "It was the year of Our Lord one thousand seven hundred and seventy-five. \n",
        "Spiritual revelations were conceded to England at that favoured period, \n",
        "as at this. Mrs. Southcott had recently attained her five-and-twentieth blessed birthday, \n",
        "of whom a prophetic private in the Life Guards had heralded the sublime appearance \n",
        "by announcing that arrangements were made for the swallowing up of London and Westminster. \n",
        "Even the Cock-lane ghost had been laid only a round dozen of years, \n",
        "after rapping out its messages, \n",
        "as the spirits of this very year last past (supernaturally deficient in originality) rapped out theirs. \n",
        "Mere messages in the earthly order of events had lately come to the English Crown and People, \n",
        "from a congress of British subjects in America: which, strange to relate, \n",
        "have proved more important to the human race than any communications yet received through any of the chickens of the Cock-lane brood.'''\n",
        "\n",
        "pluto.orig_melville_page2 = '''Call me Ishmael. \n",
        "Some years ago—never mind how long precisely—having little or no money in my purse, \n",
        "and nothing particular to interest me on shore, \n",
        "I thought I would sail about a little and see the watery part of the world. \n",
        "It is a way I have of driving off the spleen and regulating the circulation.'''\n",
        "\n",
        "pluto.orig_melville_page = '''Call me Ishmael. \n",
        "Some years ago—never mind how long precisely—having little or no money in my purse, \n",
        "and nothing particular to interest me on shore, \n",
        "I thought I would sail about a little and see the watery part of the world. \n",
        "It is a way I have of driving off the spleen and regulating the circulation. \n",
        "Whenever I find myself growing grim about the mouth; whenever it is a damp, \n",
        "drizzly November in my soul; \n",
        "whenever I find myself involuntarily pausing before coffin warehouses, \n",
        "and bringing up the rear of every funeral I meet; \n",
        "and especially whenever my hypos get such an upper hand of me, \n",
        "that it requires a strong moral principle to prevent me from deliberately stepping into the street, \n",
        "and methodically knocking people’s hats off—then, \n",
        "I account it high time to get to sea as soon as I can. \n",
        "This is my substitute for pistol and ball. \n",
        "With a philosophical flourish Cato throws himself upon his sword; \n",
        "I quietly take to the ship. There is nothing surprising in this. \n",
        "If they but knew it, almost all men in their degree, some time or other, \n",
        "cherish very nearly the same feelings towards the ocean with me.'''\n",
        "\n",
        "#\n",
        "pluto.orig_carroll_page = '''Alice was beginning to get very tired of sitting by her sister on the bank, \n",
        "and of having nothing to do. \n",
        "Once or twice she had peeped into the book her sister was reading, \n",
        "but it had no pictures or conversations in it. \n",
        "“and what is the use of a book,” thought Alice “without pictures or conversations?”\n",
        "So she was considering in her own mind. as well as she could, \n",
        "for the hot day made her feel very sleepy and stupid. \n",
        "whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, \n",
        "when suddenly a White Rabbit with pink eyes ran close by her.\n",
        "There was nothing so very remarkable in that; \n",
        "nor did Alice think it so very much out of the way to hear the Rabbit say to itself. \n",
        "“Oh dear! Oh dear! I shall be late!” \n",
        "when she thought it over afterwards, \n",
        "it occurred to her that she ought to have wondered at this, \n",
        "but at the time it all seemed quite natural; \n",
        "but when the Rabbit actually took a watch out of its waistcoat-pocket, \n",
        "and looked at it, and then hurried on, Alice started to her feet, \n",
        "for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, \n",
        "or a watch to take out of it, \n",
        "and burning with curiosity, \n",
        "she ran across the field after it, \n",
        "and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
        "'''\n",
        "#\n",
        "pluto.orig_carroll_page2 = '''Alice was beginning to get very tired of sitting by her sister on the bank, \n",
        "and of having nothing to do. \n",
        "Once or twice she had peeped into the book her sister was reading, \n",
        "but it had no pictures or conversations in it.\n",
        "“and what is the use of a book,” thought Alice “without pictures or conversations?”\n",
        "So she was considering in her own mind. as well as she could, \n",
        "for the hot day made her feel very sleepy and stupid. \n",
        "whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, \n",
        "when suddenly a White Rabbit with pink eyes ran close by her.'''\n",
        "#\n",
        "pluto.orig_self = '''Text augmentation with Machine Learning (ML) is an advanced technique. \n",
        "Ironically, Text augmentation aims to improve ML model accuracy, \n",
        "but we used a pre-trained ML model to create additional training NLP data. \n",
        "It’s a circular process. ML coding is not in this book’s scope, \n",
        "but understanding the difference between text augmentation using libraries and ML is beneficial.  \n",
        "Augmentation libraries, whether for image, text, or audio, \n",
        "follow the traditional programming methodologies with structure data, loops, \n",
        "and conditional statements in the algorithm. \n",
        "For example, from Chapter 5, the pseudo-code for implementing the method _print_aug_reserved() could be as follows:'''"
      ],
      "metadata": {
        "id": "LBiRho15VxTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _clean_text(self,x):\n",
        "  return (re.sub('[^A-Za-z0-9 .,!?#@]+', '', str(x)))"
      ],
      "metadata": {
        "id": "mgQDAvNGmlPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_netflix_data['description'] = pluto.df_netflix_data['description'].apply(pluto._clean_text)"
      ],
      "metadata": {
        "id": "LIeAnM3rmVB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO57mq6DOvZW"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -la ../model/"
      ],
      "metadata": {
        "id": "oK-3H-GCRaRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "from nlpaug.util.file.download import DownloadUtil\n",
        "\n",
        "#DownloadUtil.download_word2vec(dest_dir='.') # word2vec\n",
        "DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # GloVe\n",
        "DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # fasttext model\n"
      ],
      "metadata": {
        "id": "jnSCgVH5WzxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "try:\n",
        "  DownloadUtil.download_word2vec(dest_dir='.') # word2vec\n",
        "except Exception:\n",
        "  print('\\nIt happen frequently that this file can not be download due to too many access.')\n",
        "  print('When it failed, you can not use Word2Vec transformation/augmentation.')\n",
        "  print('You could download the file: GoogleNews-vectors-negative300.bin.gz')\n",
        "  print('From URL: https://drive.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM \\n')"
      ],
      "metadata": {
        "id": "O4vC_3iKLAOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_word2vec(self, df, \n",
        "  col_dest=\"description\",\n",
        "  action='insert',\n",
        "  model_type='word2vec',\n",
        "  model_path='GoogleNews-vectors-negative300.bin',\n",
        "  bsize=3, \n",
        "  aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.WordEmbsAug(model_type=model_type,action=action,model_path=model_path)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "IyIftW1iOqJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='insert',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "QJWmEr9CEvkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='insert',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "bpdpR53_OqMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_twitter_data,col_dest='clean_tweet',action='insert',aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "BDMnyi0aOqPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Substitute"
      ],
      "metadata": {
        "id": "2lIhZzkeS3f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_netflix_data,\n",
        "  col_dest='description',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "rFi1CQDvS6Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_word2vec(pluto.df_twitter_data,\n",
        "  col_dest='clean_tweet',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment')"
      ],
      "metadata": {
        "id": "QPJKjPGAS6Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_carroll_page], columns=['page'])\n",
        "pluto.print_aug_ai_word2vec(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "CH4qoUd9qkoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_dickens_page], columns=['page'])\n",
        "pluto.print_aug_ai_word2vec(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='Word2Vec-GoogleNews Word Embedding Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "_R3uu_gJS6cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ert6W8iPOvZa"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gKfFXMpAsQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "sTonbBjLGlvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers>=0.61.10\n",
        "import simpletransformers\n",
        "#print(simpletransformers.__version__)"
      ],
      "metadata": {
        "id": "hmfLVK_lG1ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk>=3.4.5\n",
        "!pip install gensim>=4.1.2"
      ],
      "metadata": {
        "id": "YfujVAx3G6Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_bert(self, df, \n",
        "  col_dest=\"description\",\n",
        "  action='insert',\n",
        "  model_path='bert-base-uncased',\n",
        "  bsize=3, \n",
        "  aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.ContextualWordEmbsAug(action=action,model_path=model_path)\n",
        "  #self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name,is_orig_control=is_orig_control)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "-02N5CaMULnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  action='insert',aug_name='BERT Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "dZdWtGcYT_jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  action='insert',aug_name='BERT Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "EV7EV6OoT_tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Substitute"
      ],
      "metadata": {
        "id": "VeSjdgRSVLXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  action='substitute',aug_name='BERT Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "v6QDq9oiVTMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  action='substitute',aug_name='BERT Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "r8ZvWEySVTPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ywh0jWOvZb"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_dickens_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='BERT Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgIO-PlOOvZc"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_melville_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  action='substitute',\n",
        "  aug_name='BERT Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa"
      ],
      "metadata": {
        "id": "u996W_0AVuXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  model_path='roberta-base',\n",
        "  action='insert',aug_name='Roberta Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "QJEnGQC0V7Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  model_path='roberta-base',\n",
        "  action='insert',aug_name='Roberta Embedding Insert Augment')"
      ],
      "metadata": {
        "id": "eiQ68dyJV7Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Substitute"
      ],
      "metadata": {
        "id": "WPhvZqtAXStc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_netflix_data,col_dest='description',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',aug_name='Roberta Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "aSHAE7AaV7X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_bert(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',aug_name='Roberta Embedding Substitute Augment')"
      ],
      "metadata": {
        "id": "9W-_ZidFV7bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_dickens_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',\n",
        "  aug_name='Roberta Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ],
      "metadata": {
        "id": "twdvZPN2u4BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBf4gqwmOvZc"
      },
      "outputs": [],
      "source": [
        "df_page = pandas.DataFrame([pluto.orig_melville_page], columns=['page'])\n",
        "pluto.print_aug_ai_bert(df_page,\n",
        "  col_dest='page',\n",
        "  model_path='roberta-base',\n",
        "  action='substitute',\n",
        "  aug_name='Roberta Embedding Substitute Augment',\n",
        "  bsize=1,\n",
        "  is_orig_control=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRtJ2z3_OvZj"
      },
      "source": [
        "# Back Translation "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "bfOwoGtJvkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_back_translation(self, df, col_dest=\"description\",\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  bsize=3, aug_name='Augment',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.word.BackTranslationAug(from_model_name=from_model_name,\n",
        "    to_model_name=to_model_name)\n",
        "  self._print_aug_batch(df, aug_func,col_dest=col_dest,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "2peyD4nxXytF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "TvQSRxQbXy8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/models"
      ],
      "metadata": {
        "id": "ya0J5nTybqc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "gR1AitbqXzBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-de', \n",
        "  to_model_name='facebook/wmt19-de-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> German Augment')"
      ],
      "metadata": {
        "id": "2InysGvoyBTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Russian"
      ],
      "metadata": {
        "id": "hbtGGU2__i3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_netflix_data,col_dest='description',\n",
        "  from_model_name='facebook/wmt19-en-ru', \n",
        "  to_model_name='facebook/wmt19-ru-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> Russian Augment')"
      ],
      "metadata": {
        "id": "T3GfAXRIaA4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_back_translation(pluto.df_twitter_data,col_dest='clean_tweet',\n",
        "  from_model_name='facebook/wmt19-en-ru', \n",
        "  to_model_name='facebook/wmt19-ru-en',\n",
        "  aug_name='FaceBook Back Translation: English <-> Russian Augment')"
      ],
      "metadata": {
        "id": "9o8KPJN0aA8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DshLBm_UOvZn"
      },
      "source": [
        "# T5-Base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _fetch_larger_font(self):\n",
        "  heading_properties = [('font-size', '20px')]\n",
        "  cell_properties = [('font-size', '18px'), ('text-align', 'left')]\n",
        "  dfstyle = [dict(selector=\"th\", props=heading_properties),\n",
        "    dict(selector=\"td\", props=cell_properties)]\n",
        "  return dfstyle"
      ],
      "metadata": {
        "id": "PWYurl0o-jAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "@add_method(PacktDataAug)\n",
        "def _print_aug_ai(self, orig, aug_func, \n",
        "  bsize=2, aug_name='Augmented',is_larger_font=True):\n",
        "  aug = aug_func.augment(orig)\n",
        "  data = [[aug[0]]]\n",
        "  df_aug = pandas.DataFrame(data, columns=[aug_name])\n",
        "  #\n",
        "  if (bsize > 1):\n",
        "    for i in range(bsize-1):\n",
        "      aug = aug_func.augment(orig)\n",
        "      data = [[aug[0]]]\n",
        "      t = pandas.DataFrame(data, columns=[aug_name])\n",
        "      df_aug = df_aug.append(t, ignore_index=True)\n",
        "  #\n",
        "  with pandas.option_context(\"display.max_colwidth\", None):\n",
        "    if (is_larger_font):\n",
        "      # df_aug.style.set_properties(**{'text-align': 'left'})\n",
        "      # display(df_aug.style.set_properties(**{'text-align': 'left'}))\n",
        "      display(df_aug.style.set_table_styles(self._fetch_larger_font()))\n",
        "    else:\n",
        "      display(df_aug)\n",
        "  return df_aug\n",
        "#\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_t5(self, orig, \n",
        "  bsize=2, \n",
        "  aug_name='T5_summary',\n",
        "  is_orig_control=True):\n",
        "  aug_func = nlpaug.augmenter.sentence.AbstSummAug(model_path='t5-base')\n",
        "  df = self._print_aug_ai(orig, aug_func,bsize=bsize, aug_name=aug_name)\n",
        "  return df"
      ],
      "metadata": {
        "id": "xT_x7vmz1Wfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll = pluto.print_aug_ai_t5(pluto.orig_carroll_page, bsize=1)"
      ],
      "metadata": {
        "id": "JDwH5bq36Ln-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll = pluto.print_aug_ai_t5(pluto.orig_carroll_page2, bsize=1)"
      ],
      "metadata": {
        "id": "LEhRXqR-X_fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_melville = pluto.print_aug_ai_t5(pluto.orig_melville_page, bsize=1)"
      ],
      "metadata": {
        "id": "r1oK3bhX_fyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_dickens = pluto.print_aug_ai_t5(pluto.orig_dickens_page, bsize=1)"
      ],
      "metadata": {
        "id": "mKxdKl75_f1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_self = pluto.print_aug_ai_t5(pluto.orig_self, bsize=1)"
      ],
      "metadata": {
        "id": "1K-FP4Vy_f4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentense flow"
      ],
      "metadata": {
        "id": "zC3Gsc8QyC55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug.augmenter.word\n",
        "import nlpaug.augmenter.sentence\n",
        "import nlpaug.flow\n",
        "pluto.ai_aug_glove = nlpaug.augmenter.word.WordEmbsAug(\n",
        "    model_type='glove', model_path='glove.6B.300d.txt',\n",
        "    action=\"substitute\")\n",
        "#\n",
        "pluto.ai_aug_glove.aug_p=0.5\n",
        "#\n",
        "pluto.ai_aug_bert = nlpaug.augmenter.word.ContextualWordEmbsAug(\n",
        "    model_path='bert-base-uncased', \n",
        "    action='substitute', top_k=20)\n"
      ],
      "metadata": {
        "id": "96LvpOPdNeeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile -a {pluto_chapter_6}\n",
        "\n",
        "import nlpaug\n",
        "@add_method(PacktDataAug)\n",
        "def print_aug_ai_sequential(self, df, \n",
        "  aug_name=\"T5_summary\",\n",
        "  bsize=4):\n",
        "  aug_func = nlpaug.flow.Sequential([self.ai_aug_bert, self.ai_aug_glove])\n",
        "  orig = df[aug_name][0]\n",
        "  self._print_aug_ai(orig, aug_func,bsize=bsize, aug_name=aug_name)\n",
        "  return"
      ],
      "metadata": {
        "id": "aR5dVL-RNGpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.df_t5_carroll.T5_summary[0]"
      ],
      "metadata": {
        "id": "Ux5lEe40U3Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_carroll)"
      ],
      "metadata": {
        "id": "IvOfkZG_SpQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_dickens)"
      ],
      "metadata": {
        "id": "JraL6RCQWtG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_melville)"
      ],
      "metadata": {
        "id": "TdqKW0pzWtb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pluto.print_aug_ai_sequential(pluto.df_t5_self)"
      ],
      "metadata": {
        "id": "kmz35pawWte_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# end of chapter 6\n",
        "print('end of chatper 6')"
      ],
      "metadata": {
        "id": "tzS8W--FEXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push up all changes (Optional)"
      ],
      "metadata": {
        "id": "-8QoaB1uZj5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "# !git add -A\n",
        "# !git config --global user.email \"duc.haba@gmail.com\"\n",
        "# !git config --global user.name \"duchaba\"\n",
        "# !git commit -m \"end of session\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ],
      "metadata": {
        "id": "-uqlOsMlZm5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joLMiWRhEV0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary \n",
        "\n",
        "Every chaper will begin with same base class \"PacktDataAug\".\n",
        "\n",
        "✋ FAIR WARNING:\n",
        "\n",
        "- The coding uses long and complete function path name.\n",
        "\n",
        "- Pluto wrote the code for easy to understand and not for compactness, fast execution, nor cleaverness.\n",
        "\n",
        "- Use Xterm to debug cloud server"
      ],
      "metadata": {
        "id": "X1kgd3PWEjKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install colab-xterm\n",
        "# %load_ext colabxterm\n",
        "# %xterm"
      ],
      "metadata": {
        "id": "3n1wuFxaZm9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "EUgN2zp8_Yp0",
        "dQzHcpVfXOft",
        "W0TcPpR905Wo"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}